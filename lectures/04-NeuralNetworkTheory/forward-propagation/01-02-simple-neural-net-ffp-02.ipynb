{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "113dc5b4-8b51-4594-bfc1-72a8f1e7de3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================= #\n",
    "# Course: Deep Learning Complete Course (CS-501)\n",
    "# Author: Dr. Saad Laouadi\n",
    "# Lesson: Feed Forward Propagation: Numerical Example\n",
    "#\n",
    "# Description: Numerical Example to show to perform \n",
    "#             forward pass in neural network\n",
    "#\n",
    "#\n",
    "# =======================================================================\n",
    "#.          Copyright © Dr. Saad Laouadi\n",
    "# ======================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb13308a-b25e-422f-ae1a-23253409da26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01ba982-a22d-466b-9fb9-be9b4a98be09",
   "metadata": {},
   "source": [
    "# Neural Network Implementation Requirements\n",
    "\n",
    "## Network Architecture\n",
    "- Type: Feedforward Neural Network\n",
    "- Structure: 3-2-1 (3 inputs, 2 hidden neurons, 1 output)\n",
    "- Hidden Layer Activation: ReLU\n",
    "- Output Layer Activation: Sigmoid\n",
    "\n",
    "\n",
    "## Input Layer\n",
    "- Input dimension: 3\n",
    "- Input values range: [0, 1]\n",
    "- Sample input: `[0.3, 0.5, 0.2]`\n",
    "\n",
    "## Hidden Layer\n",
    "- Number of neurons: 2\n",
    "- Weight matrix dimensions: 2×3\n",
    "- Bias vector dimension: 2\n",
    "- Weight values:\n",
    "  ```python\n",
    "  W1 = [\n",
    "      [0.5, 0.4, 0.3],  # first neuron\n",
    "      [0.4, 0.3, 0.2]   # second neuron\n",
    "  ]\n",
    "  ```\n",
    "- Bias values: `[0.4, 0.4]`\n",
    "- Activation function: ReLU\n",
    "  ```python\n",
    "  f(x) = max(0, x)\n",
    "  ```\n",
    "\n",
    "## Output Layer\n",
    "- Number of neurons: 1\n",
    "- Weight vector dimension: 1×2\n",
    "- Weight values: `[0.6, 0.7]`\n",
    "- Bias value: `0.3`\n",
    "- Activation function: Sigmoid\n",
    "  ```python\n",
    "  f(x) = 1 / (1 + e^(-x))\n",
    "  ```\n",
    "\n",
    "## Mathematical Operations\n",
    "1. Hidden Layer:\n",
    "   - Matrix multiplication: `Z1 = W1 × X + b1`\n",
    "   - Element-wise ReLU: `A1 = max(0, Z1)`\n",
    "\n",
    "2. Output Layer:\n",
    "   - Matrix multiplication: `Z2 = W2 × A1 + b2`\n",
    "   - Sigmoid activation: `Y = sigmoid(Z2)`\n",
    "\n",
    "## Expected Output\n",
    "- Single scalar value in range [0, 1]\n",
    "- For given example: ~0.802\n",
    "\n",
    "## Implementation Requirements\n",
    "- Use NumPy vectorized operations\n",
    "- Include detailed computation logging\n",
    "- Format output to 3 decimal places\n",
    "- Document step-by-step calculations\n",
    "\n",
    "## Code Organization\n",
    "- Separate activation function definitions\n",
    "- Clear parameter initialization\n",
    "- Structured forward propagation function\n",
    "- Formatted output display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b9e7cbf-db4f-4f63-9c45-b1233d5c9e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the activation functions\n",
    "\n",
    "def relu(x):\n",
    "    \"\"\"ReLU activation function\"\"\"\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"Sigmoid activation function\"\"\"\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "169cdbd4-619d-4f21-b89c-1814b9f6df9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input values\n",
    "X = np.array([0.3, 0.5, 0.2])\n",
    "\n",
    "# Hidden layer parameters\n",
    "W1 = np.array([\n",
    "    [0.5, 0.4, 0.3],  # weights for first hidden neuron\n",
    "    [0.4, 0.3, 0.2]   # weights for second hidden neuron\n",
    "])\n",
    "\n",
    "b1 = np.array([0.4, 0.4])\n",
    "\n",
    "# Output layer parameters\n",
    "W2 = np.array([0.6, 0.7])\n",
    "b2 = np.array([0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fef7f234-763f-452f-bb61-d9c9f6149709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input values:\n",
      "X = [0.3, 0.5, 0.2]\n",
      "\n",
      "Network Parameters:\n",
      "Hidden Layer:\n",
      "W1 = [\n",
      "      [0.5, 0.4, 0.3],\n",
      "      [0.4, 0.3, 0.2]\n",
      "     ]\n",
      "b1 = [0.4, 0.4]\n",
      "\n",
      "Output Layer:\n",
      "W2 = [0.6, 0.7]\n",
      "b2 = [0.3]\n",
      "\n",
      "Hidden Layer Computations:\n",
      "\n",
      "Hidden Neuron 1:\n",
      "z1_1 = (0.5 × 0.3) + (0.4 × 0.5) + (0.3 × 0.2) + 0.4\n",
      "z1_1 = 0.150 + 0.200 + 0.060 + 0.4\n",
      "z1_1 = 0.810\n",
      "a1_1 = ReLU(0.810) = 0.810\n",
      "\n",
      "Hidden Neuron 2:\n",
      "z1_2 = (0.4 × 0.3) + (0.3 × 0.5) + (0.2 × 0.2) + 0.4\n",
      "z1_2 = 0.120 + 0.150 + 0.040 + 0.4\n",
      "z1_2 = 0.710\n",
      "a1_2 = ReLU(0.710) = 0.710\n",
      "\n",
      "Output Layer Computation:\n",
      "z2 = (0.6 × 0.810) + (0.7 × 0.710) + 0.3\n",
      "z2 = 0.486 + 0.497 + 0.3\n",
      "z2 = 1.283\n",
      "y = sigmoid(1.283) = 0.783\n"
     ]
    }
   ],
   "source": [
    "# Print initial parameters\n",
    "print(\"Input values:\")\n",
    "print(f\"X = [{X[0]:.1f}, {X[1]:.1f}, {X[2]:.1f}]\")\n",
    "\n",
    "\n",
    "print(\"\\nNetwork Parameters:\")\n",
    "\n",
    "# Hidden Layer Parameters\n",
    "print(\"Hidden Layer:\")\n",
    "\n",
    "# Weight Matrix W1\n",
    "print(\"W1 = [\")\n",
    "print(f\"      [{W1[0][0]:.1f}, {W1[0][1]:.1f}, {W1[0][2]:.1f}],\")\n",
    "print(f\"      [{W1[1][0]:.1f}, {W1[1][1]:.1f}, {W1[1][2]:.1f}]\")\n",
    "print(\"     ]\")\n",
    "\n",
    "# Bias Vector b1\n",
    "print(f\"b1 = [{b1[0]:.1f}, {b1[1]:.1f}]\")\n",
    "\n",
    "print(\"\\nOutput Layer:\")\n",
    "print(f\"W2 = [{W2[0]:.1f}, {W2[1]:.1f}]\")\n",
    "print(f\"b2 = [{b2[0]:.1f}]\")\n",
    "\n",
    "# Hidden layer computation\n",
    "print(\"\\nHidden Layer Computations:\")\n",
    "\n",
    "# First hidden neuron\n",
    "z1_1 = np.dot(W1[0], X) + b1[0]\n",
    "\n",
    "print(f\"\\nHidden Neuron 1:\")\n",
    "print(f\"z1_1 = ({W1[0][0]:.1f} × {X[0]:.1f}) + \"\n",
    "      f\"({W1[0][1]:.1f} × {X[1]:.1f}) + \"\n",
    "      f\"({W1[0][2]:.1f} × {X[2]:.1f}) + {b1[0]:.1f}\")\n",
    "\n",
    "print(f\"z1_1 = {W1[0][0]*X[0]:.3f} + \"\n",
    "      f\"{W1[0][1]*X[1]:.3f} + \"\n",
    "      f\"{W1[0][2]*X[2]:.3f} + {b1[0]:.1f}\")\n",
    "\n",
    "print(f\"z1_1 = {z1_1:.3f}\")\n",
    "a1_1 = relu(z1_1)\n",
    "print(f\"a1_1 = ReLU({z1_1:.3f}) = {a1_1:.3f}\")\n",
    "\n",
    "# Second hidden neuron\n",
    "z1_2 = np.dot(W1[1], X) + b1[1]\n",
    "\n",
    "print(f\"\\nHidden Neuron 2:\")\n",
    "print(f\"z1_2 = ({W1[1][0]:.1f} × {X[0]:.1f}) + \"\n",
    "      f\"({W1[1][1]:.1f} × {X[1]:.1f}) + \"\n",
    "      f\"({W1[1][2]:.1f} × {X[2]:.1f}) + {b1[1]:.1f}\")\n",
    "\n",
    "print(f\"z1_2 = {W1[1][0]*X[0]:.3f} + \"\n",
    "      f\"{W1[1][1]*X[1]:.3f} + \"\n",
    "      f\"{W1[1][2]*X[2]:.3f} + {b1[1]:.1f}\")\n",
    "\n",
    "print(f\"z1_2 = {z1_2:.3f}\")\n",
    "a1_2 = relu(z1_2)\n",
    "print(f\"a1_2 = ReLU({z1_2:.3f}) = {a1_2:.3f}\")\n",
    "\n",
    "# Output layer computation\n",
    "print(\"\\nOutput Layer Computation:\")\n",
    "\n",
    "# Compute z2\n",
    "z2 = W2[0] * a1_1 + W2[1] * a1_2 + b2[0]\n",
    "\n",
    "# Print detailed computation steps\n",
    "print(f\"z2 = ({W2[0]:.1f} × {a1_1:.3f}) + \"\n",
    "      f\"({W2[1]:.1f} × {a1_2:.3f}) + {b2[0]:.1f}\")\n",
    "\n",
    "print(f\"z2 = {W2[0] * a1_1:.3f} + \"\n",
    "      f\"{W2[1] * a1_2:.3f} + {b2[0]:.1f}\")\n",
    "\n",
    "# Final result\n",
    "print(f\"z2 = {z2:.3f}\")\n",
    "\n",
    "y = sigmoid(z2)\n",
    "print(f\"y = sigmoid({z2:.3f}) = {y:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c64385f-cfce-4d67-899a-e9b069d50f55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF-GPU:2.16",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
