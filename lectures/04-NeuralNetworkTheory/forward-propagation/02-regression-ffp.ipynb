{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43eb9e1a-eaa3-4c18-bbd9-d9c6b8ff245c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8c2b198-5762-484a-b805-43aebdd6c843",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3091a473-0083-4d88-9274-83e9b6aeb332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c21716b1-96ee-43bb-8c1b-fe1762a735f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEURAL NETWORK FORWARD PROPAGATION\n",
      "\n",
      "INITIAL VALUES:\n",
      "Inputs: [ 2.4 -1.2  0.5]\n",
      "Input → Hidden Weights:\n",
      "[[ 0.3 -0.4  0.7]\n",
      " [ 0.2  0.5 -0.6]\n",
      " [-0.1  0.8  0.4]]\n",
      "Hidden → Output Weights: [ 0.5 -0.3  0.2]\n",
      "Hidden Layer Bias: 1.0\n",
      "Output Layer Bias: -0.5\n",
      "\n",
      "HIDDEN LAYER CALCULATIONS:\n",
      "================================================================================\n",
      "Hidden Node 1 (h_1) Calculations:\n",
      "================================================================================\n",
      "Terms:\n",
      "  ( 2.400 ×  0.300 =  0.720)\n",
      "  (-1.200 ×  0.200 = -0.240)\n",
      "  ( 0.500 × -0.100 = -0.050)\n",
      "\n",
      "Sum of terms:  0.430\n",
      "Add bias:  0.430 +  1.000 =  1.430\n",
      "Apply sigmoid activation:  0.807\n",
      "================================================================================\n",
      "Hidden Node 2 (h_2) Calculations:\n",
      "================================================================================\n",
      "Terms:\n",
      "  ( 2.400 × -0.400 = -0.960)\n",
      "  (-1.200 ×  0.500 = -0.600)\n",
      "  ( 0.500 ×  0.800 =  0.400)\n",
      "\n",
      "Sum of terms: -1.160\n",
      "Add bias: -1.160 +  1.000 = -0.160\n",
      "Apply sigmoid activation:  0.460\n",
      "================================================================================\n",
      "Hidden Node 3 (h_3) Calculations:\n",
      "================================================================================\n",
      "Terms:\n",
      "  ( 2.400 ×  0.700 =  1.680)\n",
      "  (-1.200 × -0.600 =  0.720)\n",
      "  ( 0.500 ×  0.400 =  0.200)\n",
      "\n",
      "Sum of terms:  2.600\n",
      "Add bias:  2.600 +  1.000 =  3.600\n",
      "Apply sigmoid activation:  0.973\n",
      "\n",
      "OUTPUT LAYER CALCULATIONS:\n",
      "================================================================================\n",
      "Output Node Calculations:\n",
      "================================================================================\n",
      "Terms:\n",
      "  ( 0.807 ×  0.500 =  0.403)\n",
      "  ( 0.460 × -0.300 = -0.138)\n",
      "  ( 0.973 ×  0.200 =  0.195)\n",
      "\n",
      "Sum of terms:  0.460\n",
      "Add bias:  0.460 + -0.500 = -0.040\n",
      "\n",
      "================================================================================\n",
      "FINAL RESULTS:\n",
      "================================================================================\n",
      "Input Layer:  [ 2.4 -1.2  0.5]\n",
      "Hidden Layer: [0.80690132 0.46008512 0.97340301]\n",
      "Output:       -0.039894\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self):\n",
    "        # Input layer values (as shown in diagram)\n",
    "        self.inputs = np.array([2.4, -1.2, 0.5])\n",
    "        \n",
    "        # Weights from input to hidden layer (3x3 matrix)\n",
    "        self.weights_ih = np.array([\n",
    "            [0.3, -0.4, 0.7],    # weights from input 1 to hidden nodes\n",
    "            [0.2, 0.5, -0.6],    # weights from input 2 to hidden nodes\n",
    "            [-0.1, 0.8, 0.4]     # weights from input 3 to hidden nodes\n",
    "        ])\n",
    "        \n",
    "        # Weights from hidden to output layer (3x1 vector)\n",
    "        self.weights_ho = np.array([0.5, -0.3, 0.2])\n",
    "        \n",
    "        # Bias values\n",
    "        self.bias_hidden = 1.0    # Hidden layer bias\n",
    "        self.bias_output = -0.5   # Output layer bias\n",
    "\n",
    "    def sigmoid(self, x: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Sigmoid activation function\"\"\"\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def format_calculation(self, name: str, inputs: np.ndarray, weights: np.ndarray, \n",
    "                         bias: float, show_activation: bool = True) -> str:\n",
    "        \"\"\"Format calculation steps in detail\"\"\"\n",
    "        result = f\"\\n{'='*80}\\n{name} Calculations:\\n{'='*80}\\n\"\n",
    "        \n",
    "        # Individual weight calculations\n",
    "        terms = []\n",
    "        total = 0\n",
    "        for i, (input_val, weight) in enumerate(zip(inputs, weights)):\n",
    "            product = input_val * weight\n",
    "            total += product\n",
    "            terms.append(f\"({input_val:6.3f} × {weight:6.3f} = {product:6.3f})\")\n",
    "        \n",
    "        # Show each term\n",
    "        result += \"Terms:\\n\"\n",
    "        for term in terms:\n",
    "            result += f\"  {term}\\n\"\n",
    "        \n",
    "        # Add bias\n",
    "        total += bias\n",
    "        result += f\"\\nSum of terms: {total - bias:6.3f}\"\n",
    "        result += f\"\\nAdd bias: {total - bias:6.3f} + {bias:6.3f} = {total:6.3f}\"\n",
    "        \n",
    "        # Apply activation if required\n",
    "        if show_activation:\n",
    "            activated = self.sigmoid(total)\n",
    "            result += f\"\\nApply sigmoid activation: {activated:6.3f}\"\n",
    "            return result, activated\n",
    "        \n",
    "        return result, total\n",
    "\n",
    "    def forward_propagation(self) -> tuple:\n",
    "        \"\"\"\n",
    "        Perform forward propagation and return detailed calculations\n",
    "        \"\"\"\n",
    "        output = \"NEURAL NETWORK FORWARD PROPAGATION\\n\"\n",
    "        \n",
    "        # Store all values for reference\n",
    "        values = {\n",
    "            'input': self.inputs,\n",
    "            'hidden': np.zeros(3),\n",
    "            'output': 0\n",
    "        }\n",
    "        \n",
    "        # Show initial values\n",
    "        output += f\"\\nINITIAL VALUES:\"\n",
    "        output += f\"\\nInputs: {self.inputs}\"\n",
    "        output += f\"\\nInput → Hidden Weights:\\n{self.weights_ih}\"\n",
    "        output += f\"\\nHidden → Output Weights: {self.weights_ho}\"\n",
    "        output += f\"\\nHidden Layer Bias: {self.bias_hidden}\"\n",
    "        output += f\"\\nOutput Layer Bias: {self.bias_output}\"\n",
    "        \n",
    "        # Hidden Layer Calculations\n",
    "        output += \"\\n\\nHIDDEN LAYER CALCULATIONS:\"\n",
    "        for i in range(3):\n",
    "            calc, activated = self.format_calculation(\n",
    "                f\"Hidden Node {i+1} (h_{i+1})\",\n",
    "                self.inputs,\n",
    "                self.weights_ih[:, i],\n",
    "                self.bias_hidden\n",
    "            )\n",
    "            output += calc\n",
    "            values['hidden'][i] = activated\n",
    "        \n",
    "        # Output Layer Calculations\n",
    "        output += \"\\n\\nOUTPUT LAYER CALCULATIONS:\"\n",
    "        calc, final_output = self.format_calculation(\n",
    "            \"Output Node\",\n",
    "            values['hidden'],\n",
    "            self.weights_ho,\n",
    "            self.bias_output,\n",
    "            show_activation=False  # No activation for regression output\n",
    "        )\n",
    "        output += calc\n",
    "        values['output'] = final_output\n",
    "        \n",
    "        # Final Summary\n",
    "        output += f\"\\n\\n{'='*80}\\nFINAL RESULTS:\\n{'='*80}\"\n",
    "        output += f\"\\nInput Layer:  {values['input']}\"\n",
    "        output += f\"\\nHidden Layer: {values['hidden']}\"\n",
    "        output += f\"\\nOutput:       {values['output']:.6f}\"\n",
    "        \n",
    "        return values, output\n",
    "\n",
    "def main():\n",
    "    # Create and run the neural network\n",
    "    nn = NeuralNetwork()\n",
    "    _, detailed_output = nn.forward_propagation()\n",
    "    \n",
    "    # Print the detailed calculations\n",
    "    print(detailed_output)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457bb047-63c9-45a9-bd6e-5551a28551b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d3389e6-6dfb-4820-a720-925c2ce00388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "NEURAL NETWORK FORWARD PROPAGATION\n",
      "================================================================================\n",
      "\n",
      "INITIAL VALUES:\n",
      "Inputs: [ 2.4 -1.2  0.5]\n",
      "Hidden layer weights:\n",
      "[[ 0.3 -0.4  0.7]\n",
      " [ 0.2  0.5 -0.6]\n",
      " [-0.1  0.8  0.4]]\n",
      "Output weights: [ 0.5 -0.3  0.2]\n",
      "Hidden bias: 1.0\n",
      "Output bias: -0.5\n",
      "\n",
      "CALCULATIONS:\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Hidden Node 1:\n",
      "Raw calculation: (2.400 × 0.300) + (-1.200 × 0.200) + (0.500 × -0.100) + 1.000 (bias)\n",
      "Weighted sum: 1.430\n",
      "After activation: 0.807\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Hidden Node 2:\n",
      "Raw calculation: (2.400 × -0.400) + (-1.200 × 0.500) + (0.500 × 0.800) + 1.000 (bias)\n",
      "Weighted sum: -0.160\n",
      "After activation: 0.460\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Hidden Node 3:\n",
      "Raw calculation: (2.400 × 0.700) + (-1.200 × -0.600) + (0.500 × 0.400) + 1.000 (bias)\n",
      "Weighted sum: 3.600\n",
      "After activation: 0.973\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Output Node:\n",
      "Raw calculation: (0.807 × 0.500) + (0.460 × -0.300) + (0.973 × 0.200) + -0.500 (bias)\n",
      "Weighted sum: -0.040\n",
      "After activation: 0.490\n",
      "\n",
      "================================================================================\n",
      "FINAL RESULTS:\n",
      "\n",
      "Hidden Layer Values:\n",
      "h1: 0.807\n",
      "h2: 0.460\n",
      "h3: 0.973\n",
      "\n",
      "Final Output: 0.490\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self):\n",
    "        # Input layer values\n",
    "        self.inputs = np.array([2.4, -1.2, 0.5])\n",
    "        \n",
    "        # Weights from input to hidden layer\n",
    "        self.weights_ih = np.array([\n",
    "            [0.3, -0.4, 0.7],    # weights from input 1 to hidden nodes\n",
    "            [0.2, 0.5, -0.6],    # weights from input 2 to hidden nodes\n",
    "            [-0.1, 0.8, 0.4]     # weights from input 3 to hidden nodes\n",
    "        ])\n",
    "        \n",
    "        # Weights from hidden to output layer\n",
    "        self.weights_ho = np.array([0.5, -0.3, 0.2])\n",
    "        \n",
    "        # Bias values\n",
    "        self.bias_hidden = 1.0\n",
    "        self.bias_output = -0.5\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        \"\"\"Sigmoid activation function\"\"\"\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def format_calculation(self, operation_name, inputs, weights, bias, result):\n",
    "        \"\"\"Format calculation steps\"\"\"\n",
    "        calc_str = f\"\\n{'-'*80}\\n{operation_name}:\\n\"\n",
    "        \n",
    "        # Format each term in the weighted sum\n",
    "        terms = [f\"({input:.3f} × {weight:.3f})\" \n",
    "                for input, weight in zip(inputs, weights)]\n",
    "        \n",
    "        calc_str += f\"Raw calculation: {' + '.join(terms)}\"\n",
    "        if bias is not None:\n",
    "            calc_str += f\" + {bias:.3f} (bias)\"\n",
    "        \n",
    "        # Calculate intermediate sum before activation\n",
    "        weighted_sum = np.dot(inputs, weights) + (bias if bias is not None else 0)\n",
    "        calc_str += f\"\\nWeighted sum: {weighted_sum:.3f}\"\n",
    "        \n",
    "        if result != weighted_sum:  # If activation was applied\n",
    "            calc_str += f\"\\nAfter activation: {result:.3f}\"\n",
    "            \n",
    "        return calc_str\n",
    "\n",
    "    def forward_propagation(self):\n",
    "        \"\"\"Perform forward propagation through the network\"\"\"\n",
    "        print(f\"\\n{'='*80}\\nNEURAL NETWORK FORWARD PROPAGATION\\n{'='*80}\")\n",
    "        \n",
    "        # Display initial values\n",
    "        print(\"\\nINITIAL VALUES:\")\n",
    "        print(f\"Inputs: {self.inputs}\")\n",
    "        print(f\"Hidden layer weights:\\n{self.weights_ih}\")\n",
    "        print(f\"Output weights: {self.weights_ho}\")\n",
    "        print(f\"Hidden bias: {self.bias_hidden}\")\n",
    "        print(f\"Output bias: {self.bias_output}\")\n",
    "        \n",
    "        print(\"\\nCALCULATIONS:\")\n",
    "        \n",
    "        # Calculate hidden layer values\n",
    "        hidden_raw = []\n",
    "        hidden_activated = []\n",
    "        \n",
    "        for i in range(3):  # For each hidden node\n",
    "            weights = self.weights_ih[:, i]\n",
    "            raw_value = np.dot(self.inputs, weights) + self.bias_hidden\n",
    "            activated_value = self.sigmoid(raw_value)\n",
    "            \n",
    "            hidden_raw.append(raw_value)\n",
    "            hidden_activated.append(activated_value)\n",
    "            \n",
    "            # Format and display calculation for this hidden node\n",
    "            print(self.format_calculation(\n",
    "                f\"Hidden Node {i+1}\",\n",
    "                self.inputs,\n",
    "                weights,\n",
    "                self.bias_hidden,\n",
    "                activated_value\n",
    "            ))\n",
    "        \n",
    "        hidden_layer = np.array(hidden_activated)\n",
    "        \n",
    "        # Calculate output\n",
    "        output_raw = np.dot(hidden_layer, self.weights_ho) + self.bias_output\n",
    "        final_output = self.sigmoid(output_raw)\n",
    "        \n",
    "        # Format and display output calculation\n",
    "        print(self.format_calculation(\n",
    "            \"Output Node\",\n",
    "            hidden_layer,\n",
    "            self.weights_ho,\n",
    "            self.bias_output,\n",
    "            final_output\n",
    "        ))\n",
    "        \n",
    "        # Display final results summary\n",
    "        print(f\"\\n{'='*80}\\nFINAL RESULTS:\\n\")\n",
    "        print(\"Hidden Layer Values:\")\n",
    "        for i, value in enumerate(hidden_layer, 1):\n",
    "            print(f\"h{i}: {value:.3f}\")\n",
    "        print(f\"\\nFinal Output: {final_output:.3f}\")\n",
    "        \n",
    "        return final_output\n",
    "\n",
    "# Create and run the neural network\n",
    "nn = NeuralNetwork()\n",
    "output = nn.forward_propagation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ef72b4d-bafe-45d0-bae3-dfc2d5e4e6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEURAL NETWORK FORWARD PROPAGATION WITH TWO HIDDEN LAYERS\n",
      "\n",
      "****************************************************************************************************\n",
      "INITIAL VALUES:\n",
      "Inputs: [ 2.4 -1.2  0.5]\n",
      "First Hidden Layer Weights:\n",
      "[[ 0.3 -0.4  0.7]\n",
      " [ 0.2  0.5 -0.6]\n",
      " [-0.1  0.8  0.4]]\n",
      "Second Hidden Layer Weights:\n",
      "[[ 0.4 -0.2  0.3]\n",
      " [-0.5  0.6  0.1]\n",
      " [ 0.2 -0.4  0.7]]\n",
      "Output Weights: [ 0.5 -0.3  0.2]\n",
      "Biases: h1=1.0, h2=0.8, o=-0.5\n",
      "####################################################################################################\n",
      "FIRST HIDDEN LAYER\n",
      "####################################################################################################\n",
      "====================================================================================================\n",
      "Node 1 Calculations:\n",
      "====================================================================================================\n",
      "Weighted sum: ( 2.400 ×  0.300 =  0.720) + (-1.200 ×  0.200 = -0.240) + ( 0.500 × -0.100 = -0.050) +  1.000 (bias)\n",
      "Total sum:  1.430\n",
      "After sigmoid activation:  0.807\n",
      "\n",
      "====================================================================================================\n",
      "Node 2 Calculations:\n",
      "====================================================================================================\n",
      "Weighted sum: ( 2.400 × -0.400 = -0.960) + (-1.200 ×  0.500 = -0.600) + ( 0.500 ×  0.800 =  0.400) +  1.000 (bias)\n",
      "Total sum: -0.160\n",
      "After sigmoid activation:  0.460\n",
      "\n",
      "====================================================================================================\n",
      "Node 3 Calculations:\n",
      "====================================================================================================\n",
      "Weighted sum: ( 2.400 ×  0.700 =  1.680) + (-1.200 × -0.600 =  0.720) + ( 0.500 ×  0.400 =  0.200) +  1.000 (bias)\n",
      "Total sum:  3.600\n",
      "After sigmoid activation:  0.973\n",
      "\n",
      "####################################################################################################\n",
      "SECOND HIDDEN LAYER\n",
      "####################################################################################################\n",
      "====================================================================================================\n",
      "Node 1 Calculations:\n",
      "====================================================================================================\n",
      "Weighted sum: ( 0.807 ×  0.400 =  0.323) + ( 0.460 × -0.500 = -0.230) + ( 0.973 ×  0.200 =  0.195) +  0.800 (bias)\n",
      "Total sum:  1.087\n",
      "After sigmoid activation:  0.748\n",
      "\n",
      "====================================================================================================\n",
      "Node 2 Calculations:\n",
      "====================================================================================================\n",
      "Weighted sum: ( 0.807 × -0.200 = -0.161) + ( 0.460 ×  0.600 =  0.276) + ( 0.973 × -0.400 = -0.389) +  0.800 (bias)\n",
      "Total sum:  0.525\n",
      "After sigmoid activation:  0.628\n",
      "\n",
      "====================================================================================================\n",
      "Node 3 Calculations:\n",
      "====================================================================================================\n",
      "Weighted sum: ( 0.807 ×  0.300 =  0.242) + ( 0.460 ×  0.100 =  0.046) + ( 0.973 ×  0.700 =  0.681) +  0.800 (bias)\n",
      "Total sum:  1.769\n",
      "After sigmoid activation:  0.854\n",
      "\n",
      "####################################################################################################\n",
      "OUTPUT LAYER\n",
      "####################################################################################################\n",
      "====================================================================================================\n",
      "OUTPUT LAYER Calculations:\n",
      "====================================================================================================\n",
      "Weighted sum: ( 0.748 ×  0.500 =  0.374) + ( 0.628 × -0.300 = -0.189) + ( 0.854 ×  0.200 =  0.171) + -0.500 (bias)\n",
      "Total sum: -0.144\n",
      "After sigmoid activation:  0.464\n",
      "\n",
      "====================================================================================================\n",
      "FINAL RESULTS:\n",
      "====================================================================================================\n",
      "Layer Values:\n",
      "Input Layer:          [ 2.4 -1.2  0.5]\n",
      "First Hidden Layer:   [0.80690132 0.46008512 0.97340301]\n",
      "Second Hidden Layer:  [0.74789154 0.62838849 0.85439063]\n",
      "Output:               0.4641385203638542\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Two Hidden Nodes\n",
    "import numpy as np\n",
    "from typing import Tuple, List, Dict\n",
    "import json\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self):\n",
    "        # Input layer values (3 nodes)\n",
    "        self.inputs = np.array([2.4, -1.2, 0.5])\n",
    "        \n",
    "        # Weights from input to first hidden layer (3x3 matrix)\n",
    "        self.weights_ih1 = np.array([\n",
    "            [0.3, -0.4, 0.7],    # weights from input 1 to hidden1 nodes\n",
    "            [0.2, 0.5, -0.6],    # weights from input 2 to hidden1 nodes\n",
    "            [-0.1, 0.8, 0.4]     # weights from input 3 to hidden1 nodes\n",
    "        ])\n",
    "        \n",
    "        # Weights from first to second hidden layer (3x3 matrix)\n",
    "        self.weights_h1h2 = np.array([\n",
    "            [0.4, -0.2, 0.3],    # weights from hidden1_1 to hidden2 nodes\n",
    "            [-0.5, 0.6, 0.1],    # weights from hidden1_2 to hidden2 nodes\n",
    "            [0.2, -0.4, 0.7]     # weights from hidden1_3 to hidden2 nodes\n",
    "        ])\n",
    "        \n",
    "        # Weights from second hidden to output layer (3x1 vector)\n",
    "        self.weights_h2o = np.array([0.5, -0.3, 0.2])\n",
    "        \n",
    "        # Bias values\n",
    "        self.bias_h1 = 1.0    # First hidden layer bias\n",
    "        self.bias_h2 = 0.8    # Second hidden layer bias\n",
    "        self.bias_o = -0.5    # Output layer bias\n",
    "\n",
    "    def sigmoid(self, x: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Sigmoid activation function\"\"\"\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def format_vector_calculation(self, name: str, inputs: np.ndarray, \n",
    "                                weights: np.ndarray, bias: float) -> str:\n",
    "        \"\"\"Format calculation steps for a vector operation\"\"\"\n",
    "        result = f\"\\n{'='*100}\\n{name} Calculations:\\n{'='*100}\\n\"\n",
    "        \n",
    "        # Format each weight calculation\n",
    "        terms = []\n",
    "        for i, (inp, weight) in enumerate(zip(inputs, weights)):\n",
    "            terms.append(f\"({inp:6.3f} × {weight:6.3f} = {inp*weight:6.3f})\")\n",
    "        \n",
    "        # Show the complete calculation\n",
    "        result += \"Weighted sum: \" + \" + \".join(terms)\n",
    "        if bias is not None:\n",
    "            result += f\" + {bias:6.3f} (bias)\"\n",
    "        \n",
    "        # Calculate and show the sum\n",
    "        weighted_sum = np.dot(inputs, weights) + (bias if bias is not None else 0)\n",
    "        result += f\"\\nTotal sum: {weighted_sum:6.3f}\"\n",
    "        \n",
    "        # Show activation result\n",
    "        activated = self.sigmoid(weighted_sum)\n",
    "        result += f\"\\nAfter sigmoid activation: {activated:6.3f}\\n\"\n",
    "        \n",
    "        return result, activated\n",
    "\n",
    "    def format_layer_calculations(self, name: str, inputs: np.ndarray, \n",
    "                                weights: np.ndarray, bias: float) -> str:\n",
    "        \"\"\"Format calculations for an entire layer\"\"\"\n",
    "        result = f\"\\n{'#'*100}\\n{name}\\n{'#'*100}\"\n",
    "        activated_values = []\n",
    "        \n",
    "        for i in range(weights.shape[1]):\n",
    "            layer_calc, activated = self.format_vector_calculation(\n",
    "                f\"Node {i+1}\",\n",
    "                inputs,\n",
    "                weights[:, i],\n",
    "                bias\n",
    "            )\n",
    "            result += layer_calc\n",
    "            activated_values.append(activated)\n",
    "        \n",
    "        return result, np.array(activated_values)\n",
    "\n",
    "    def forward_propagation(self) -> Tuple[Dict[str, np.ndarray], str]:\n",
    "        \"\"\"\n",
    "        Perform forward propagation through the network and return detailed calculations\n",
    "        \"\"\"\n",
    "        output = \"NEURAL NETWORK FORWARD PROPAGATION WITH TWO HIDDEN LAYERS\\n\"\n",
    "        \n",
    "        # Store all layer values for reference\n",
    "        layer_values = {\n",
    "            'input': self.inputs\n",
    "        }\n",
    "        \n",
    "        # Input layer information\n",
    "        output += f\"\\n{'*'*100}\"\n",
    "        output += \"\\nINITIAL VALUES:\"\n",
    "        output += f\"\\nInputs: {self.inputs}\"\n",
    "        output += f\"\\nFirst Hidden Layer Weights:\\n{self.weights_ih1}\"\n",
    "        output += f\"\\nSecond Hidden Layer Weights:\\n{self.weights_h1h2}\"\n",
    "        output += f\"\\nOutput Weights: {self.weights_h2o}\"\n",
    "        output += f\"\\nBiases: h1={self.bias_h1}, h2={self.bias_h2}, o={self.bias_o}\"\n",
    "        \n",
    "        # First Hidden Layer Calculations\n",
    "        h1_calc, h1_values = self.format_layer_calculations(\n",
    "            \"FIRST HIDDEN LAYER\", \n",
    "            self.inputs, \n",
    "            self.weights_ih1, \n",
    "            self.bias_h1\n",
    "        )\n",
    "        output += h1_calc\n",
    "        layer_values['hidden1'] = h1_values\n",
    "        \n",
    "        # Second Hidden Layer Calculations\n",
    "        h2_calc, h2_values = self.format_layer_calculations(\n",
    "            \"SECOND HIDDEN LAYER\", \n",
    "            h1_values, \n",
    "            self.weights_h1h2, \n",
    "            self.bias_h2\n",
    "        )\n",
    "        output += h2_calc\n",
    "        layer_values['hidden2'] = h2_values\n",
    "        \n",
    "        # Output Layer Calculation\n",
    "        o_calc, o_value = self.format_vector_calculation(\n",
    "            \"OUTPUT LAYER\", \n",
    "            h2_values, \n",
    "            self.weights_h2o, \n",
    "            self.bias_o\n",
    "        )\n",
    "        output += f\"\\n{'#'*100}\\nOUTPUT LAYER\\n{'#'*100}\"\n",
    "        output += o_calc\n",
    "        layer_values['output'] = o_value\n",
    "        \n",
    "        # Final Summary\n",
    "        output += f\"\\n{'='*100}\\nFINAL RESULTS:\\n{'='*100}\\n\"\n",
    "        output += \"Layer Values:\\n\"\n",
    "        output += f\"Input Layer:          {layer_values['input']}\\n\"\n",
    "        output += f\"First Hidden Layer:   {layer_values['hidden1']}\\n\"\n",
    "        output += f\"Second Hidden Layer:  {layer_values['hidden2']}\\n\"\n",
    "        output += f\"Output:               {layer_values['output']}\\n\"\n",
    "        \n",
    "        return layer_values, output\n",
    "\n",
    "def main():\n",
    "    # Create and run the neural network\n",
    "    nn = NeuralNetwork()\n",
    "    layer_values, detailed_output = nn.forward_propagation()\n",
    "    \n",
    "    # Print the detailed calculations\n",
    "    print(detailed_output)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac391932-ad19-4d96-8a8c-83d613018f0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6adb2dd2-17ad-408f-b0d5-189acb755d62",
   "metadata": {},
   "source": [
    "# Classification Forward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55f658aa-aef7-4758-9c98-2afe41a42cb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Classification Example with One Hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e04da27-6f8d-419a-893f-e0911bb3c5c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "NEURAL NETWORK FORWARD PROPAGATION\n",
      "Single Hidden Layer with Two Outputs\n",
      "====================================================================================================\n",
      "\n",
      "NETWORK CONFIGURATION:\n",
      "Input values: [ 2.4 -1.2  0.5]\n",
      "\n",
      "Weights (Input → Hidden):\n",
      "[[ 0.3 -0.4  0.7]\n",
      " [ 0.2  0.5 -0.6]\n",
      " [-0.1  0.8  0.4]]\n",
      "\n",
      "Weights (Hidden → Output):\n",
      "[[ 0.5  0.4]\n",
      " [-0.3  0.6]\n",
      " [ 0.2 -0.3]]\n",
      "\n",
      "Bias values:\n",
      "  Hidden layer: 1.0\n",
      "  Output layer: [-0.5  0.4]\n",
      "####################################################################################################\n",
      "HIDDEN LAYER\n",
      "####################################################################################################\n",
      "====================================================================================================\n",
      "Node 1 Calculations:\n",
      "====================================================================================================\n",
      "Terms: ( 2.400 ×  0.300) + (-1.200 ×  0.200) + ( 0.500 × -0.100) +  1.000 (bias)\n",
      "Weighted terms: [ 0.720, -0.240, -0.050]\n",
      "Weighted sum:  1.430\n",
      "After sigmoid activation:  0.807\n",
      "\n",
      "====================================================================================================\n",
      "Node 2 Calculations:\n",
      "====================================================================================================\n",
      "Terms: ( 2.400 × -0.400) + (-1.200 ×  0.500) + ( 0.500 ×  0.800) +  1.000 (bias)\n",
      "Weighted terms: [-0.960, -0.600,  0.400]\n",
      "Weighted sum: -0.160\n",
      "After sigmoid activation:  0.460\n",
      "\n",
      "====================================================================================================\n",
      "Node 3 Calculations:\n",
      "====================================================================================================\n",
      "Terms: ( 2.400 ×  0.700) + (-1.200 × -0.600) + ( 0.500 ×  0.400) +  1.000 (bias)\n",
      "Weighted terms: [ 1.680,  0.720,  0.200]\n",
      "Weighted sum:  3.600\n",
      "After sigmoid activation:  0.973\n",
      "\n",
      "####################################################################################################\n",
      "OUTPUT LAYER\n",
      "####################################################################################################\n",
      "====================================================================================================\n",
      "Node 1 Calculations:\n",
      "====================================================================================================\n",
      "Terms: ( 0.807 ×  0.500) + ( 0.460 × -0.300) + ( 0.973 ×  0.200) + -0.500 (bias)\n",
      "Weighted terms: [ 0.403, -0.138,  0.195]\n",
      "Weighted sum: -0.040\n",
      "After sigmoid activation:  0.490\n",
      "\n",
      "====================================================================================================\n",
      "Node 2 Calculations:\n",
      "====================================================================================================\n",
      "Terms: ( 0.807 ×  0.400) + ( 0.460 ×  0.600) + ( 0.973 × -0.300) +  0.400 (bias)\n",
      "Weighted terms: [ 0.323,  0.276, -0.292]\n",
      "Weighted sum:  0.707\n",
      "After sigmoid activation:  0.670\n",
      "\n",
      "====================================================================================================\n",
      "FINAL RESULTS\n",
      "====================================================================================================\n",
      "\n",
      "Layer Values:\n",
      "Input Layer:   [ 2.4 -1.2  0.5]\n",
      "Hidden Layer:  [0.80690132 0.46008512 0.97340301]\n",
      "Output Layer:\n",
      "  Output 1:    0.490028\n",
      "  Output 2:    0.669692\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from typing import Tuple, Dict\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self):\n",
    "        # Input layer values (3 nodes)\n",
    "        self.inputs = np.array([2.4, -1.2, 0.5])\n",
    "        \n",
    "        # Weights from input to hidden layer (3x3 matrix)\n",
    "        self.weights_ih = np.array([\n",
    "            [0.3, -0.4, 0.7],    # weights from input 1 to hidden nodes\n",
    "            [0.2, 0.5, -0.6],    # weights from input 2 to hidden nodes\n",
    "            [-0.1, 0.8, 0.4]     # weights from input 3 to hidden nodes\n",
    "        ])\n",
    "        \n",
    "        # Weights from hidden to output layer (3x2 matrix)\n",
    "        self.weights_ho = np.array([\n",
    "            [0.5, 0.4],     # weights from hidden 1 to output nodes\n",
    "            [-0.3, 0.6],    # weights from hidden 2 to output nodes\n",
    "            [0.2, -0.3]     # weights from hidden 3 to output nodes\n",
    "        ])\n",
    "        \n",
    "        # Bias values\n",
    "        self.bias_hidden = 1.0               # Hidden layer bias\n",
    "        self.bias_output = np.array([-0.5, 0.4])  # Output layer biases\n",
    "\n",
    "    def sigmoid(self, x: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Sigmoid activation function\"\"\"\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def format_vector_calculation(self, name: str, inputs: np.ndarray, \n",
    "                                weights: np.ndarray, bias: float) -> Tuple[str, float]:\n",
    "        \"\"\"Format calculation steps for a vector operation\"\"\"\n",
    "        result = f\"\\n{'='*100}\\n{name} Calculations:\\n{'='*100}\\n\"\n",
    "        \n",
    "        # Format each weight calculation\n",
    "        terms = []\n",
    "        weighted_terms = []\n",
    "        for i, (inp, weight) in enumerate(zip(inputs, weights)):\n",
    "            terms.append(f\"({inp:6.3f} × {weight:6.3f})\")\n",
    "            weighted_terms.append(inp * weight)\n",
    "            \n",
    "        # Show the complete calculation\n",
    "        result += \"Terms: \" + \" + \".join(terms)\n",
    "        if bias is not None:\n",
    "            result += f\" + {bias:6.3f} (bias)\"\n",
    "        \n",
    "        # Show individual results\n",
    "        result += \"\\nWeighted terms: [\"\n",
    "        result += \", \".join([f\"{term:6.3f}\" for term in weighted_terms])\n",
    "        result += \"]\"\n",
    "        \n",
    "        # Calculate and show the sum\n",
    "        weighted_sum = np.sum(weighted_terms) + (bias if bias is not None else 0)\n",
    "        result += f\"\\nWeighted sum: {weighted_sum:6.3f}\"\n",
    "        \n",
    "        # Show activation result\n",
    "        activated = self.sigmoid(weighted_sum)\n",
    "        result += f\"\\nAfter sigmoid activation: {activated:6.3f}\\n\"\n",
    "        \n",
    "        return result, activated\n",
    "\n",
    "    def format_layer_calculations(self, name: str, inputs: np.ndarray, \n",
    "                                weights: np.ndarray, bias: float) -> Tuple[str, np.ndarray]:\n",
    "        \"\"\"Format calculations for an entire layer\"\"\"\n",
    "        result = f\"\\n{'#'*100}\\n{name}\\n{'#'*100}\"\n",
    "        activated_values = []\n",
    "        \n",
    "        for i in range(weights.shape[1]):\n",
    "            layer_calc, activated = self.format_vector_calculation(\n",
    "                f\"Node {i+1}\",\n",
    "                inputs,\n",
    "                weights[:, i],\n",
    "                bias if np.isscalar(bias) else bias[i]\n",
    "            )\n",
    "            result += layer_calc\n",
    "            activated_values.append(activated)\n",
    "        \n",
    "        return result, np.array(activated_values)\n",
    "\n",
    "    def forward_propagation(self) -> Tuple[Dict[str, np.ndarray], str]:\n",
    "        \"\"\"\n",
    "        Perform forward propagation through the network and return detailed calculations\n",
    "        \"\"\"\n",
    "        output = f\"{'='*100}\\n\"\n",
    "        output += \"NEURAL NETWORK FORWARD PROPAGATION\\n\"\n",
    "        output += f\"Single Hidden Layer with Two Outputs\\n{'='*100}\\n\"\n",
    "        \n",
    "        # Store all layer values\n",
    "        layer_values = {\n",
    "            'input': self.inputs\n",
    "        }\n",
    "        \n",
    "        # Display initial values\n",
    "        output += \"\\nNETWORK CONFIGURATION:\"\n",
    "        output += f\"\\nInput values: {self.inputs}\"\n",
    "        output += f\"\\n\\nWeights (Input → Hidden):\\n{self.weights_ih}\"\n",
    "        output += f\"\\n\\nWeights (Hidden → Output):\\n{self.weights_ho}\"\n",
    "        output += f\"\\n\\nBias values:\"\n",
    "        output += f\"\\n  Hidden layer: {self.bias_hidden}\"\n",
    "        output += f\"\\n  Output layer: {self.bias_output}\"\n",
    "        \n",
    "        # Hidden Layer Calculations\n",
    "        hidden_calc, hidden_values = self.format_layer_calculations(\n",
    "            \"HIDDEN LAYER\", \n",
    "            self.inputs, \n",
    "            self.weights_ih, \n",
    "            self.bias_hidden\n",
    "        )\n",
    "        output += hidden_calc\n",
    "        layer_values['hidden'] = hidden_values\n",
    "        \n",
    "        # Output Layer Calculations\n",
    "        output_calc, output_values = self.format_layer_calculations(\n",
    "            \"OUTPUT LAYER\", \n",
    "            hidden_values, \n",
    "            self.weights_ho, \n",
    "            self.bias_output\n",
    "        )\n",
    "        output += output_calc\n",
    "        layer_values['output'] = output_values\n",
    "        \n",
    "        # Final Summary\n",
    "        output += f\"\\n{'='*100}\\nFINAL RESULTS\\n{'='*100}\\n\"\n",
    "        output += \"\\nLayer Values:\"\n",
    "        output += f\"\\nInput Layer:   {layer_values['input']}\"\n",
    "        output += f\"\\nHidden Layer:  {layer_values['hidden']}\"\n",
    "        output += \"\\nOutput Layer:\"\n",
    "        output += f\"\\n  Output 1:    {layer_values['output'][0]:.6f}\"\n",
    "        output += f\"\\n  Output 2:    {layer_values['output'][1]:.6f}\"\n",
    "        \n",
    "        return layer_values, output\n",
    "\n",
    "def main():\n",
    "    # Create and run the neural network\n",
    "    nn = NeuralNetwork()\n",
    "    _, detailed_output = nn.forward_propagation()\n",
    "    \n",
    "    # Print the detailed calculations\n",
    "    print(detailed_output)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e4384d-fedb-4716-9615-6bab9ee20eee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "164a33a8-47d6-42a4-a48f-eedc8be966a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEURAL NETWORK FORWARD PROPAGATION WITH TWO HIDDEN LAYERS AND TWO OUTPUTS\n",
      "\n",
      "****************************************************************************************************\n",
      "INITIAL VALUES:\n",
      "Inputs: [ 2.4 -1.2  0.5]\n",
      "First Hidden Layer Weights:\n",
      "[[ 0.3 -0.4  0.7]\n",
      " [ 0.2  0.5 -0.6]\n",
      " [-0.1  0.8  0.4]]\n",
      "Second Hidden Layer Weights:\n",
      "[[ 0.4 -0.2  0.3]\n",
      " [-0.5  0.6  0.1]\n",
      " [ 0.2 -0.4  0.7]]\n",
      "Output Layer Weights:\n",
      "[[ 0.5  0.4]\n",
      " [-0.3  0.6]\n",
      " [ 0.2 -0.3]]\n",
      "Biases: h1=1.0, h2=0.8, o=[-0.5  0.4]\n",
      "####################################################################################################\n",
      "FIRST HIDDEN LAYER\n",
      "####################################################################################################\n",
      "====================================================================================================\n",
      "Node 1 Calculations:\n",
      "====================================================================================================\n",
      "Weighted sum: ( 2.400 ×  0.300 =  0.720) + (-1.200 ×  0.200 = -0.240) + ( 0.500 × -0.100 = -0.050) +  1.000 (bias)\n",
      "Total sum:  1.430\n",
      "After sigmoid activation:  0.807\n",
      "\n",
      "====================================================================================================\n",
      "Node 2 Calculations:\n",
      "====================================================================================================\n",
      "Weighted sum: ( 2.400 × -0.400 = -0.960) + (-1.200 ×  0.500 = -0.600) + ( 0.500 ×  0.800 =  0.400) +  1.000 (bias)\n",
      "Total sum: -0.160\n",
      "After sigmoid activation:  0.460\n",
      "\n",
      "====================================================================================================\n",
      "Node 3 Calculations:\n",
      "====================================================================================================\n",
      "Weighted sum: ( 2.400 ×  0.700 =  1.680) + (-1.200 × -0.600 =  0.720) + ( 0.500 ×  0.400 =  0.200) +  1.000 (bias)\n",
      "Total sum:  3.600\n",
      "After sigmoid activation:  0.973\n",
      "\n",
      "####################################################################################################\n",
      "SECOND HIDDEN LAYER\n",
      "####################################################################################################\n",
      "====================================================================================================\n",
      "Node 1 Calculations:\n",
      "====================================================================================================\n",
      "Weighted sum: ( 0.807 ×  0.400 =  0.323) + ( 0.460 × -0.500 = -0.230) + ( 0.973 ×  0.200 =  0.195) +  0.800 (bias)\n",
      "Total sum:  1.087\n",
      "After sigmoid activation:  0.748\n",
      "\n",
      "====================================================================================================\n",
      "Node 2 Calculations:\n",
      "====================================================================================================\n",
      "Weighted sum: ( 0.807 × -0.200 = -0.161) + ( 0.460 ×  0.600 =  0.276) + ( 0.973 × -0.400 = -0.389) +  0.800 (bias)\n",
      "Total sum:  0.525\n",
      "After sigmoid activation:  0.628\n",
      "\n",
      "====================================================================================================\n",
      "Node 3 Calculations:\n",
      "====================================================================================================\n",
      "Weighted sum: ( 0.807 ×  0.300 =  0.242) + ( 0.460 ×  0.100 =  0.046) + ( 0.973 ×  0.700 =  0.681) +  0.800 (bias)\n",
      "Total sum:  1.769\n",
      "After sigmoid activation:  0.854\n",
      "\n",
      "####################################################################################################\n",
      "OUTPUT LAYER\n",
      "####################################################################################################\n",
      "====================================================================================================\n",
      "Output Node 1 Calculations:\n",
      "====================================================================================================\n",
      "Weighted sum: ( 0.748 ×  0.500 =  0.374) + ( 0.628 × -0.300 = -0.189) + ( 0.854 ×  0.200 =  0.171) + -0.500 (bias)\n",
      "Total sum: -0.144\n",
      "After sigmoid activation:  0.464\n",
      "\n",
      "====================================================================================================\n",
      "Output Node 2 Calculations:\n",
      "====================================================================================================\n",
      "Weighted sum: ( 0.748 ×  0.400 =  0.299) + ( 0.628 ×  0.600 =  0.377) + ( 0.854 × -0.300 = -0.256) +  0.400 (bias)\n",
      "Total sum:  0.820\n",
      "After sigmoid activation:  0.694\n",
      "\n",
      "====================================================================================================\n",
      "FINAL RESULTS:\n",
      "====================================================================================================\n",
      "Layer Values:\n",
      "Input Layer:          [ 2.4 -1.2  0.5]\n",
      "First Hidden Layer:   [0.80690132 0.46008512 0.97340301]\n",
      "Second Hidden Layer:  [0.74789154 0.62838849 0.85439063]\n",
      "Output Layer:\n",
      "  Output 1:           0.464\n",
      "  Output 2:           0.694\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Two Hidden Layers Two Output nodes: Classification \n",
    "# ==================================================\n",
    "\n",
    "import numpy as np\n",
    "from typing import Tuple, List, Dict\n",
    "import json\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self):\n",
    "        # Input layer values (3 nodes)\n",
    "        self.inputs = np.array([2.4, -1.2, 0.5])\n",
    "        \n",
    "        # Weights from input to first hidden layer (3x3 matrix)\n",
    "        self.weights_ih1 = np.array([\n",
    "            [0.3, -0.4, 0.7],    # weights from input 1 to hidden1 nodes\n",
    "            [0.2, 0.5, -0.6],    # weights from input 2 to hidden1 nodes\n",
    "            [-0.1, 0.8, 0.4]     # weights from input 3 to hidden1 nodes\n",
    "        ])\n",
    "        \n",
    "        # Weights from first to second hidden layer (3x3 matrix)\n",
    "        self.weights_h1h2 = np.array([\n",
    "            [0.4, -0.2, 0.3],    # weights from hidden1_1 to hidden2 nodes\n",
    "            [-0.5, 0.6, 0.1],    # weights from hidden1_2 to hidden2 nodes\n",
    "            [0.2, -0.4, 0.7]     # weights from hidden1_3 to hidden2 nodes\n",
    "        ])\n",
    "        \n",
    "        # Weights from second hidden to output layer (3x2 matrix)\n",
    "        self.weights_h2o = np.array([\n",
    "            [0.5, 0.4],     # weights from hidden2_1 to output nodes\n",
    "            [-0.3, 0.6],    # weights from hidden2_2 to output nodes\n",
    "            [0.2, -0.3]     # weights from hidden2_3 to output nodes\n",
    "        ])\n",
    "        \n",
    "        # Bias values\n",
    "        self.bias_h1 = 1.0                # First hidden layer bias\n",
    "        self.bias_h2 = 0.8                # Second hidden layer bias\n",
    "        self.bias_o = np.array([-0.5, 0.4])  # Output layer biases\n",
    "\n",
    "    def sigmoid(self, x: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Sigmoid activation function\"\"\"\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def format_vector_calculation(self, name: str, inputs: np.ndarray, \n",
    "                                weights: np.ndarray, bias: float) -> str:\n",
    "        \"\"\"Format calculation steps for a vector operation\"\"\"\n",
    "        result = f\"\\n{'='*100}\\n{name} Calculations:\\n{'='*100}\\n\"\n",
    "        \n",
    "        # Format each weight calculation\n",
    "        terms = []\n",
    "        for i, (inp, weight) in enumerate(zip(inputs, weights)):\n",
    "            terms.append(f\"({inp:6.3f} × {weight:6.3f} = {inp*weight:6.3f})\")\n",
    "        \n",
    "        # Show the complete calculation\n",
    "        result += \"Weighted sum: \" + \" + \".join(terms)\n",
    "        if bias is not None:\n",
    "            result += f\" + {bias:6.3f} (bias)\"\n",
    "        \n",
    "        # Calculate and show the sum\n",
    "        weighted_sum = np.dot(inputs, weights) + (bias if bias is not None else 0)\n",
    "        result += f\"\\nTotal sum: {weighted_sum:6.3f}\"\n",
    "        \n",
    "        # Show activation result\n",
    "        activated = self.sigmoid(weighted_sum)\n",
    "        result += f\"\\nAfter sigmoid activation: {activated:6.3f}\\n\"\n",
    "        \n",
    "        return result, activated\n",
    "\n",
    "    def format_layer_calculations(self, name: str, inputs: np.ndarray, \n",
    "                                weights: np.ndarray, bias: float) -> str:\n",
    "        \"\"\"Format calculations for an entire layer\"\"\"\n",
    "        result = f\"\\n{'#'*100}\\n{name}\\n{'#'*100}\"\n",
    "        activated_values = []\n",
    "        \n",
    "        for i in range(weights.shape[1]):\n",
    "            layer_calc, activated = self.format_vector_calculation(\n",
    "                f\"Node {i+1}\",\n",
    "                inputs,\n",
    "                weights[:, i],\n",
    "                bias if np.isscalar(bias) else bias[i]\n",
    "            )\n",
    "            result += layer_calc\n",
    "            activated_values.append(activated)\n",
    "        \n",
    "        return result, np.array(activated_values)\n",
    "\n",
    "    def forward_propagation(self) -> Tuple[Dict[str, np.ndarray], str]:\n",
    "        \"\"\"\n",
    "        Perform forward propagation through the network and return detailed calculations\n",
    "        \"\"\"\n",
    "        output = \"NEURAL NETWORK FORWARD PROPAGATION WITH TWO HIDDEN LAYERS AND TWO OUTPUTS\\n\"\n",
    "        \n",
    "        # Store all layer values for reference\n",
    "        layer_values = {\n",
    "            'input': self.inputs\n",
    "        }\n",
    "        \n",
    "        # Input layer information\n",
    "        output += f\"\\n{'*'*100}\"\n",
    "        output += \"\\nINITIAL VALUES:\"\n",
    "        output += f\"\\nInputs: {self.inputs}\"\n",
    "        output += f\"\\nFirst Hidden Layer Weights:\\n{self.weights_ih1}\"\n",
    "        output += f\"\\nSecond Hidden Layer Weights:\\n{self.weights_h1h2}\"\n",
    "        output += f\"\\nOutput Layer Weights:\\n{self.weights_h2o}\"\n",
    "        output += f\"\\nBiases: h1={self.bias_h1}, h2={self.bias_h2}, o={self.bias_o}\"\n",
    "        \n",
    "        # First Hidden Layer Calculations\n",
    "        h1_calc, h1_values = self.format_layer_calculations(\n",
    "            \"FIRST HIDDEN LAYER\", \n",
    "            self.inputs, \n",
    "            self.weights_ih1, \n",
    "            self.bias_h1\n",
    "        )\n",
    "        output += h1_calc\n",
    "        layer_values['hidden1'] = h1_values\n",
    "        \n",
    "        # Second Hidden Layer Calculations\n",
    "        h2_calc, h2_values = self.format_layer_calculations(\n",
    "            \"SECOND HIDDEN LAYER\", \n",
    "            h1_values, \n",
    "            self.weights_h1h2, \n",
    "            self.bias_h2\n",
    "        )\n",
    "        output += h2_calc\n",
    "        layer_values['hidden2'] = h2_values\n",
    "        \n",
    "        # Output Layer Calculations\n",
    "        output_calc = f\"\\n{'#'*100}\\nOUTPUT LAYER\\n{'#'*100}\"\n",
    "        output_values = []\n",
    "        \n",
    "        for i in range(self.weights_h2o.shape[1]):\n",
    "            calc, activated = self.format_vector_calculation(\n",
    "                f\"Output Node {i+1}\",\n",
    "                h2_values,\n",
    "                self.weights_h2o[:, i],\n",
    "                self.bias_o[i]\n",
    "            )\n",
    "            output_calc += calc\n",
    "            output_values.append(activated)\n",
    "        \n",
    "        output += output_calc\n",
    "        layer_values['output'] = np.array(output_values)\n",
    "        \n",
    "        # Final Summary\n",
    "        output += f\"\\n{'='*100}\\nFINAL RESULTS:\\n{'='*100}\\n\"\n",
    "        output += \"Layer Values:\\n\"\n",
    "        output += f\"Input Layer:          {layer_values['input']}\\n\"\n",
    "        output += f\"First Hidden Layer:   {layer_values['hidden1']}\\n\"\n",
    "        output += f\"Second Hidden Layer:  {layer_values['hidden2']}\\n\"\n",
    "        output += \"Output Layer:\\n\"\n",
    "        output += f\"  Output 1:           {layer_values['output'][0]:.3f}\\n\"\n",
    "        output += f\"  Output 2:           {layer_values['output'][1]:.3f}\\n\"\n",
    "        \n",
    "        return layer_values, output\n",
    "\n",
    "def main():\n",
    "    # Create and run the neural network\n",
    "    nn = NeuralNetwork()\n",
    "    layer_values, detailed_output = nn.forward_propagation()\n",
    "    \n",
    "    # Print the detailed calculations\n",
    "    print(detailed_output)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808558c2-aa25-4a4a-982c-8d96e4133570",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF-GPU:2.16",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
