{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "297156c1-7deb-4c1d-b601-7a156476a408",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center;font-size:22pt; font-weight:bold;color:white;border:solid black 1.5pt;background-color:#1e7263;\">\n",
    "    TensorBoard Callback Overview\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "131fa24a-96cf-4cc5-a2a7-945b355942c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================= #\n",
    "# Course: Deep Learning Complete Course (CS-501)\n",
    "# Author: Dr. Saad Laouadi\n",
    "# Institution: Quant Coding Versity Academy\n",
    "# Date: December 25, 2024\n",
    "#\n",
    "# ==========================================================\n",
    "# Lesson: Learning Rate Adaptation with ReduceLROnPlateau\n",
    "#         Synthetic Data Example\n",
    "# ==========================================================\n",
    "# ## Learning Objectives\n",
    "# This example will enable you to:\n",
    "# 1. Create synthetic data for learning rate adaptation\n",
    "# 2. Implement ReduceLROnPlateau callback\n",
    "# 3. Monitor learning rate changes during training\n",
    "# 4. Visualize the impact of learning rate reduction\n",
    "# 5. Compare training with and without adaptive learning rates\n",
    "# =======================================================================\n",
    "#          Copyright © Dr. Saad Laouadi 2024\n",
    "# ======================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f199023-5275-440c-8e26-061d374c72c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ============================================================================ #\n",
    "#                         Environment Path Configuration                       #\n",
    "# ============================================================================ #\n",
    "#\n",
    "# Purpose:\n",
    "#   Configure the system PATH to use Python executables from the active virtual \n",
    "#   environment instead of global installations.\n",
    "#\n",
    "# Usage:\n",
    "#   1. First verify if configuration is needed by running: !which python\n",
    "#   2. If the output shows the global Python installation rather than your \n",
    "#      virtual environment, execute this configuration block\n",
    "#\n",
    "# Note:\n",
    "#   This configuration is typically only needed for JupyterLab Desktop or \n",
    "#   similar standalone installations. Web-based JupyterLab or properly \n",
    "#   configured environments should not require this adjustment.\n",
    "# ============================================================================ #\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "env_path = os.path.dirname(sys.executable)\n",
    "os.environ['PATH'] = f\"{env_path}:{os.environ['PATH']}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c45e74e-8b50-48ae-9f2f-99bd8d350f63",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================\n",
      "Author: Dr. Saad Laouadi\n",
      "\n",
      "Last updated: 2025-01-09\n",
      "\n",
      "Compiler    : Clang 14.0.6 \n",
      "OS          : Darwin\n",
      "Release     : 24.1.0\n",
      "Machine     : arm64\n",
      "Processor   : arm\n",
      "CPU cores   : 16\n",
      "Architecture: 64bit\n",
      "\n",
      "========================================================================\n",
      "Imported Packages and Their Versions:\n",
      "========================================================================\n",
      "psutil    : 5.9.0\n",
      "sys       : 3.11.10 (main, Oct  3 2024, 02:26:51) [Clang 14.0.6 ]\n",
      "numpy     : 1.26.4\n",
      "tensorflow: 2.16.2\n",
      "seaborn   : 0.13.2\n",
      "sklearn   : 1.5.1\n",
      "pandas    : 2.2.2\n",
      "matplotlib: 3.9.2\n",
      "\n",
      "========================================================================\n"
     ]
    }
   ],
   "source": [
    "# ==================================================== #\n",
    "#        Load Required Libraries\n",
    "# ==================================================== #\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import io\n",
    "\n",
    "# Disable Metal API Validation\n",
    "os.environ[\"METAL_DEVICE_WRAPPER_TYPE\"] = \"0\"  \n",
    "\n",
    "import psutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# import tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set styling for better visualization\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"=\"*72)\n",
    "\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Dr. Saad Laouadi\" -u -d -m\n",
    "\n",
    "print(\"=\"*72)\n",
    "print(\"Imported Packages and Their Versions:\")\n",
    "print(\"=\"*72)\n",
    "\n",
    "%watermark -iv\n",
    "print(\"=\"*72)\n",
    "\n",
    "# Global Config\n",
    "RANDOM_STATE = 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44fbc7b1-be5c-496b-a1b4-2bd697016faf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Educational Utility Function: Directory Cleanup\n",
    "# =============================================================================\n",
    "#\n",
    "# Purpose:\n",
    "#   This utility function is designed for educational purposes in the context\n",
    "#   of programming tutorials and exercises. It provides a safe way to clean up\n",
    "#   working directories during course activities.\n",
    "#\n",
    "# Usage Context:\n",
    "#   - Instructors: Useful for preparing and resetting educational content\n",
    "#   - Students: Helpful when experimenting with code examples\n",
    "#   - Learning Environment: Supports clean workspace management\n",
    "#\n",
    "# Note:\n",
    "#   This function is intended for educational environments only and should be\n",
    "#   used with caution as it permanently deletes directory contents.\n",
    "# =============================================================================\n",
    "\n",
    "def cleanup_directory(directory_path):\n",
    "    \"\"\"\n",
    "    Deletes the specified directory and all its contents.\n",
    "    Args:\n",
    "        directory_path (str): Path to the directory to delete.\n",
    "    \"\"\"\n",
    "    if os.path.exists(directory_path) and os.path.isdir(directory_path):\n",
    "        shutil.rmtree(directory_path)\n",
    "        print(f\"Directory '{os.path.basename(directory_path)}' deleted successfully.\")\n",
    "    else:\n",
    "        print(f\"Directory '{os.path.basename(directory_path)}' does not exist or is not a directory.\")\n",
    "        \n",
    "        \n",
    "# tensorboard cleanup        \n",
    "def cleanup_tensorboard():\n",
    "    \"\"\"\n",
    "    Cleanup TensorBoard processes professionally\n",
    "    \"\"\"\n",
    "    # Find and terminate TensorBoard processes\n",
    "    for proc in psutil.process_iter(['pid', 'name']):\n",
    "        try:\n",
    "            # Look for tensorboard processes\n",
    "            if 'tensorboard' in proc.info['name'].lower():\n",
    "                # Terminate gracefully\n",
    "                process = psutil.Process(proc.info['pid'])\n",
    "                process.terminate()\n",
    "                print(f\"TensorBoard process {proc.info['pid']} terminated gracefully\")\n",
    "        except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875bdf5f-d329-4d7c-9d56-9ce1ff159182",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f23b31c-ee97-41d3-aa28-cae6114cd5b0",
   "metadata": {},
   "source": [
    "### Requirements\n",
    "\n",
    "This notebook needs the following tools to run without errors. You can install the next tools from within a notebook cell without leaving this working environment. \n",
    "\n",
    "I recommend running this first\n",
    "\n",
    "```python\n",
    "import os\n",
    "import sys\n",
    "\n",
    "env_path = os.path.dirname(sys.executable)\n",
    "os.environ['PATH'] = f\"{env_path}:{os.environ['PATH']}\"\n",
    "```\n",
    "\n",
    "Check the cell {[2]} above for more information. \n",
    "\n",
    "\n",
    "1. **The `psutil` package**: You might need to install `psutil` if you haven't already by running the next command:\n",
    "\n",
    "```python\n",
    "!pip install psutil\n",
    "```\n",
    "\n",
    "2. **The `tensorboard` package**: You may install `tensorboard` by running this command\n",
    "\n",
    "```bash\n",
    "!pip install tensorboard\n",
    "```\n",
    "\n",
    "If the somethind did not go as expected, you may need to check this [tensorboard overview](07-04-00-callbacks-tensorboard-overview.ipynb) for more details on to setup your environment to use `tensorboard`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd874e58-88b9-4010-8c71-9cf1ad67d093",
   "metadata": {},
   "source": [
    "### Raodmap\n",
    "1. Load and process House prices Data\n",
    "2. Create Model with `tensorboard` callback\n",
    "4. Use and interpret the results on tensorboard visualization tool\n",
    "5. Use more advanced model with multiple callbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3befe902-33e8-48fb-af01-08e4f5195e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================= #\n",
    "#          California House Prices Regression Project\n",
    "# ================================================================= #\n",
    "\n",
    "# A function to load and process the data\n",
    "def load_and_preprocess_data(random_state=0):\n",
    "    \"\"\"Load and preprocess the California Housing dataset\"\"\"\n",
    "    # Load data\n",
    "    housing = fetch_california_housing()\n",
    "    X, y = housing.data, housing.target\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=random_state\n",
    "    )\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled, y_train, y_test, housing.feature_names\n",
    "\n",
    "# Create a function to build and compile the model\n",
    "def create_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(8,)),  # California Housing has 8 features\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dense(1)  # Single output for regression\n",
    "    ])\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='mse',  # Mean Squared Error for regression\n",
    "        metrics=[\n",
    "            'mae',  # Mean Absolute Error\n",
    "            'mse'   # Mean Squared Error\n",
    "        ]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca27830d-1f8f-4e15-9c53-92d55834b052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory for logs with meaningful name\n",
    "model_name = \"california_housing\"\n",
    "log_dir = os.path.join(\"logs\", \"fit\", model_name, datetime.now().strftime('%Y%m%d-%H%M%S'))\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# Create TensorBoard callback with modern configuration\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=log_dir,\n",
    "    histogram_freq=1,              # Enable histogram computation each epoch\n",
    "    write_graph=True,\n",
    "    write_images=False,            # Usually not needed, can make logs very large\n",
    "    update_freq='epoch',\n",
    "    profile_batch=(5, 10)          # Profile batches 5 through 10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8691216-8fc1-407e-a1fc-b40f43388070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TensorBoard extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Clear previous logs (optional)\n",
    "!rm -rf logs/fit\n",
    "\n",
    "# Create the model\n",
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81bd268b-8da7-4c63-8a5c-6500482c35e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 2.3288 - mae: 1.0588 - mse: 2.3288 - val_loss: 0.4368 - val_mae: 0.4725 - val_mse: 0.4368\n",
      "Epoch 2/50\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.4471 - mae: 0.4710 - mse: 0.4471 - val_loss: 0.3766 - val_mae: 0.4515 - val_mse: 0.3766\n",
      "Epoch 3/50\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.3942 - mae: 0.4502 - mse: 0.3942 - val_loss: 0.3524 - val_mae: 0.4314 - val_mse: 0.3524\n",
      "Epoch 4/50\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.3674 - mae: 0.4318 - mse: 0.3674 - val_loss: 0.3395 - val_mae: 0.4236 - val_mse: 0.3395\n",
      "Epoch 5/50\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.3706 - mae: 0.4302 - mse: 0.3706 - val_loss: 0.3383 - val_mae: 0.4316 - val_mse: 0.3383\n",
      "Epoch 6/50\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.3529 - mae: 0.4126 - mse: 0.3529 - val_loss: 0.3358 - val_mae: 0.4028 - val_mse: 0.3358\n",
      "Epoch 7/50\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.3374 - mae: 0.4126 - mse: 0.3374 - val_loss: 0.3200 - val_mae: 0.4044 - val_mse: 0.3200\n",
      "Epoch 8/50\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.3208 - mae: 0.3998 - mse: 0.3208 - val_loss: 0.3125 - val_mae: 0.4024 - val_mse: 0.3125\n",
      "Epoch 9/50\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.3263 - mae: 0.3949 - mse: 0.3263 - val_loss: 0.3080 - val_mae: 0.3971 - val_mse: 0.3080\n",
      "Epoch 10/50\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.3175 - mae: 0.3938 - mse: 0.3175 - val_loss: 0.3012 - val_mae: 0.3821 - val_mse: 0.3012\n",
      "Epoch 11/50\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.3372 - mae: 0.3938 - mse: 0.3372 - val_loss: 0.3141 - val_mae: 0.3837 - val_mse: 0.3141\n",
      "Epoch 12/50\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.3024 - mae: 0.3777 - mse: 0.3024 - val_loss: 0.3231 - val_mae: 0.3981 - val_mse: 0.3231\n",
      "Epoch 13/50\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.3225 - mae: 0.3869 - mse: 0.3225 - val_loss: 0.2963 - val_mae: 0.3846 - val_mse: 0.2963\n",
      "Epoch 14/50\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.3293 - mae: 0.3775 - mse: 0.3293 - val_loss: 0.2967 - val_mae: 0.3862 - val_mse: 0.2967\n",
      "Epoch 15/50\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.3041 - mae: 0.3814 - mse: 0.3041 - val_loss: 0.3001 - val_mae: 0.3809 - val_mse: 0.3001\n",
      "Epoch 16/50\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.2958 - mae: 0.3749 - mse: 0.2958 - val_loss: 0.2949 - val_mae: 0.3859 - val_mse: 0.2949\n",
      "Epoch 17/50\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.3001 - mae: 0.3761 - mse: 0.3001 - val_loss: 0.2894 - val_mae: 0.3747 - val_mse: 0.2894\n",
      "Epoch 18/50\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.3113 - mae: 0.3735 - mse: 0.3113 - val_loss: 0.3003 - val_mae: 0.3736 - val_mse: 0.3003\n",
      "Epoch 19/50\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.3124 - mae: 0.3739 - mse: 0.3124 - val_loss: 0.2871 - val_mae: 0.3752 - val_mse: 0.2871\n",
      "Epoch 20/50\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.2779 - mae: 0.3643 - mse: 0.2779 - val_loss: 0.2987 - val_mae: 0.3756 - val_mse: 0.2987\n",
      "Epoch 21/50\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.2985 - mae: 0.3774 - mse: 0.2985 - val_loss: 0.2844 - val_mae: 0.3702 - val_mse: 0.2844\n",
      "Epoch 22/50\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.2898 - mae: 0.3687 - mse: 0.2898 - val_loss: 0.2839 - val_mae: 0.3738 - val_mse: 0.2839\n",
      "Epoch 23/50\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.2796 - mae: 0.3651 - mse: 0.2796 - val_loss: 0.2796 - val_mae: 0.3683 - val_mse: 0.2796\n",
      "Epoch 24/50\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.2770 - mae: 0.3610 - mse: 0.2770 - val_loss: 0.2827 - val_mae: 0.3711 - val_mse: 0.2827\n",
      "Epoch 25/50\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.2804 - mae: 0.3634 - mse: 0.2804 - val_loss: 0.2821 - val_mae: 0.3666 - val_mse: 0.2821\n",
      "Epoch 26/50\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.2817 - mae: 0.3663 - mse: 0.2817 - val_loss: 0.2905 - val_mae: 0.3799 - val_mse: 0.2905\n",
      "Epoch 27/50\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.2676 - mae: 0.3582 - mse: 0.2676 - val_loss: 0.2911 - val_mae: 0.3931 - val_mse: 0.2911\n",
      "Epoch 28/50\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.2669 - mae: 0.3592 - mse: 0.2669 - val_loss: 0.2888 - val_mae: 0.3729 - val_mse: 0.2888\n",
      "Epoch 29/50\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.2884 - mae: 0.3661 - mse: 0.2884 - val_loss: 0.2819 - val_mae: 0.3734 - val_mse: 0.2819\n",
      "Epoch 30/50\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.2730 - mae: 0.3623 - mse: 0.2730 - val_loss: 0.2789 - val_mae: 0.3646 - val_mse: 0.2789\n",
      "Epoch 31/50\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.2742 - mae: 0.3550 - mse: 0.2742 - val_loss: 0.2727 - val_mae: 0.3612 - val_mse: 0.2727\n",
      "Epoch 32/50\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.2671 - mae: 0.3549 - mse: 0.2671 - val_loss: 0.2753 - val_mae: 0.3582 - val_mse: 0.2753\n",
      "Epoch 33/50\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.2757 - mae: 0.3576 - mse: 0.2757 - val_loss: 0.2791 - val_mae: 0.3665 - val_mse: 0.2791\n",
      "Epoch 34/50\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.2723 - mae: 0.3568 - mse: 0.2723 - val_loss: 0.2682 - val_mae: 0.3593 - val_mse: 0.2682\n",
      "Epoch 35/50\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.2607 - mae: 0.3509 - mse: 0.2607 - val_loss: 0.2758 - val_mae: 0.3691 - val_mse: 0.2758\n",
      "Epoch 36/50\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.2652 - mae: 0.3513 - mse: 0.2652 - val_loss: 0.2827 - val_mae: 0.3667 - val_mse: 0.2827\n",
      "Epoch 37/50\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.2580 - mae: 0.3484 - mse: 0.2580 - val_loss: 0.2810 - val_mae: 0.3677 - val_mse: 0.2810\n",
      "Epoch 38/50\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.2840 - mae: 0.3552 - mse: 0.2840 - val_loss: 0.2724 - val_mae: 0.3634 - val_mse: 0.2724\n",
      "Epoch 39/50\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.2684 - mae: 0.3526 - mse: 0.2684 - val_loss: 0.2767 - val_mae: 0.3642 - val_mse: 0.2767\n",
      "Epoch 40/50\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.2476 - mae: 0.3461 - mse: 0.2476 - val_loss: 0.2726 - val_mae: 0.3634 - val_mse: 0.2726\n",
      "Epoch 41/50\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.2576 - mae: 0.3476 - mse: 0.2576 - val_loss: 0.2764 - val_mae: 0.3610 - val_mse: 0.2764\n",
      "Epoch 42/50\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.2483 - mae: 0.3417 - mse: 0.2483 - val_loss: 0.2755 - val_mae: 0.3570 - val_mse: 0.2755\n",
      "Epoch 43/50\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.2488 - mae: 0.3418 - mse: 0.2488 - val_loss: 0.2655 - val_mae: 0.3578 - val_mse: 0.2655\n",
      "Epoch 44/50\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.2571 - mae: 0.3459 - mse: 0.2571 - val_loss: 0.2784 - val_mae: 0.3652 - val_mse: 0.2784\n",
      "Epoch 45/50\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.2492 - mae: 0.3447 - mse: 0.2492 - val_loss: 0.2848 - val_mae: 0.3614 - val_mse: 0.2848\n",
      "Epoch 46/50\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.2601 - mae: 0.3504 - mse: 0.2601 - val_loss: 0.2767 - val_mae: 0.3585 - val_mse: 0.2767\n",
      "Epoch 47/50\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.2532 - mae: 0.3433 - mse: 0.2532 - val_loss: 0.2745 - val_mae: 0.3626 - val_mse: 0.2745\n",
      "Epoch 48/50\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.2559 - mae: 0.3471 - mse: 0.2559 - val_loss: 0.2638 - val_mae: 0.3518 - val_mse: 0.2638\n",
      "Epoch 49/50\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.2454 - mae: 0.3396 - mse: 0.2454 - val_loss: 0.2786 - val_mae: 0.3737 - val_mse: 0.2786\n",
      "Epoch 50/50\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.2662 - mae: 0.3541 - mse: 0.2662 - val_loss: 0.2666 - val_mae: 0.3541 - val_mse: 0.2666\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 99236), started 0:36:01 ago. (Use '!kill 99236' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-dc8dad4ad88e2797\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-dc8dad4ad88e2797\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load and preprocess data\n",
    "X_train, X_test, y_train, y_test, feature_names = load_and_preprocess_data()\n",
    "        \n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50,              # Increased epochs for better training\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[tensorboard_callback],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Launch TensorBoard\n",
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f932869-9c19-4e6b-ba44-706e3156ebef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use before starting a new TensorBoard session\n",
    "cleanup_tensorboard()\n",
    "\n",
    "# Clear any previous logs\n",
    "!rm -rf california_housing/logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b7adbf-8039-491b-ad7a-0c9a39b30f48",
   "metadata": {},
   "source": [
    "### Running Advanced Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b25d94e7-8d27-417b-a451-556944a31b55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_advanced_model():\n",
    "    \"\"\"Create advanced model architecture for california house prices project.\"\"\"\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(8,)),\n",
    "        \n",
    "        # First block with residual connection\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        \n",
    "        # Second block with residual connection\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        \n",
    "        # Third block\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.1),\n",
    "        \n",
    "        # Output layer\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='mse',\n",
    "        metrics=[\n",
    "            'mae',\n",
    "            tf.keras.metrics.RootMeanSquaredError(name='rmse')\n",
    "        ]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Load and preprocess data\n",
    "X_train, X_test, y_train, y_test, feature_names = load_and_preprocess_data()\n",
    "\n",
    "# Set up callbacks\n",
    "def create_callbacks(model_name=\"california_housing\"):\n",
    "    \"\"\"Create all callbacks for training\"\"\"\n",
    "    \n",
    "    # Create directories for logs and checkpoints\n",
    "    base_dir = \"training_logs\"\n",
    "    log_dir = os.path.join(base_dir, \"logs\", model_name, datetime.now().strftime('%Y%m%d-%H%M%S'))\n",
    "    checkpoint_dir = os.path.join(base_dir, \"checkpoints\", model_name)\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    \n",
    "    callbacks = [\n",
    "        # TensorBoard callback\n",
    "        tf.keras.callbacks.TensorBoard(\n",
    "            log_dir=log_dir,\n",
    "            histogram_freq=1,\n",
    "            write_graph=True,\n",
    "            write_images=False,\n",
    "            update_freq='epoch',\n",
    "            profile_batch=(5, 10)\n",
    "        ),\n",
    "        \n",
    "        # Model checkpoint callback\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath=os.path.join(checkpoint_dir, 'model_{epoch:02d}-{val_loss:.4f}.keras'),\n",
    "            save_best_only=True,\n",
    "            monitor='val_loss',\n",
    "            mode='min',\n",
    "            verbose=1\n",
    "        ),\n",
    "        \n",
    "        # Early stopping callback\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=10,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        \n",
    "        # Reduce LR on plateau callback\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.2,\n",
    "            patience=5,\n",
    "            min_lr=1e-6,\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97994dea-8fb7-4e0d-91c0-9cd997b182f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Clean up previous TensorBoard sessions\n",
    "%reload_ext tensorboard\n",
    "!rm -rf training_logs/logs/*\n",
    "\n",
    "# Create and train the model\n",
    "model = create_advanced_model()\n",
    "callbacks = create_callbacks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52bc1293-059f-44b5-a286-33af70e3e5b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.6513 - mae: 1.5217 - rmse: 1.8832\n",
      "Epoch 1: val_loss improved from inf to 0.54148, saving model to training_logs/checkpoints/california_housing/model_01-0.5415.keras\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 3.6478 - mae: 1.5208 - rmse: 1.8823 - val_loss: 0.5415 - val_mae: 0.5346 - val_rmse: 0.7359 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m411/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.8522 - mae: 0.6983 - rmse: 0.9227\n",
      "Epoch 2: val_loss improved from 0.54148 to 0.43051, saving model to training_logs/checkpoints/california_housing/model_02-0.4305.keras\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 0.8517 - mae: 0.6980 - rmse: 0.9224 - val_loss: 0.4305 - val_mae: 0.4641 - val_rmse: 0.6561 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m411/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.6371 - mae: 0.5989 - rmse: 0.7981\n",
      "Epoch 3: val_loss improved from 0.43051 to 0.40270, saving model to training_logs/checkpoints/california_housing/model_03-0.4027.keras\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 0.6370 - mae: 0.5988 - rmse: 0.7980 - val_loss: 0.4027 - val_mae: 0.4515 - val_rmse: 0.6346 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m412/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.5955 - mae: 0.5673 - rmse: 0.7713\n",
      "Epoch 4: val_loss improved from 0.40270 to 0.37382, saving model to training_logs/checkpoints/california_housing/model_04-0.3738.keras\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 0.5954 - mae: 0.5672 - rmse: 0.7712 - val_loss: 0.3738 - val_mae: 0.4327 - val_rmse: 0.6114 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m412/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.5225 - mae: 0.5315 - rmse: 0.7226\n",
      "Epoch 5: val_loss improved from 0.37382 to 0.34815, saving model to training_logs/checkpoints/california_housing/model_05-0.3482.keras\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 0.5225 - mae: 0.5315 - rmse: 0.7225 - val_loss: 0.3482 - val_mae: 0.4184 - val_rmse: 0.5900 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m411/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.4931 - mae: 0.5120 - rmse: 0.7022\n",
      "Epoch 6: val_loss did not improve from 0.34815\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 0.4931 - mae: 0.5120 - rmse: 0.7021 - val_loss: 0.3722 - val_mae: 0.4287 - val_rmse: 0.6101 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.4637 - mae: 0.4973 - rmse: 0.6808\n",
      "Epoch 7: val_loss did not improve from 0.34815\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 0.4637 - mae: 0.4973 - rmse: 0.6808 - val_loss: 0.3665 - val_mae: 0.4267 - val_rmse: 0.6054 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m412/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.4409 - mae: 0.4834 - rmse: 0.6640\n",
      "Epoch 8: val_loss did not improve from 0.34815\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 0.4410 - mae: 0.4834 - rmse: 0.6640 - val_loss: 0.3634 - val_mae: 0.4314 - val_rmse: 0.6029 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m410/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.4504 - mae: 0.4900 - rmse: 0.6709\n",
      "Epoch 9: val_loss improved from 0.34815 to 0.34193, saving model to training_logs/checkpoints/california_housing/model_09-0.3419.keras\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 0.4503 - mae: 0.4899 - rmse: 0.6709 - val_loss: 0.3419 - val_mae: 0.4037 - val_rmse: 0.5847 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m411/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.4344 - mae: 0.4747 - rmse: 0.6589\n",
      "Epoch 10: val_loss improved from 0.34193 to 0.33617, saving model to training_logs/checkpoints/california_housing/model_10-0.3362.keras\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 0.4343 - mae: 0.4747 - rmse: 0.6589 - val_loss: 0.3362 - val_mae: 0.4172 - val_rmse: 0.5798 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m412/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.4226 - mae: 0.4705 - rmse: 0.6500\n",
      "Epoch 11: val_loss did not improve from 0.33617\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 0.4226 - mae: 0.4705 - rmse: 0.6500 - val_loss: 0.3410 - val_mae: 0.4196 - val_rmse: 0.5840 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m412/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.4125 - mae: 0.4644 - rmse: 0.6421\n",
      "Epoch 12: val_loss improved from 0.33617 to 0.32993, saving model to training_logs/checkpoints/california_housing/model_12-0.3299.keras\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 0.4125 - mae: 0.4644 - rmse: 0.6421 - val_loss: 0.3299 - val_mae: 0.4186 - val_rmse: 0.5744 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m412/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3970 - mae: 0.4556 - rmse: 0.6300\n",
      "Epoch 13: val_loss improved from 0.32993 to 0.32562, saving model to training_logs/checkpoints/california_housing/model_13-0.3256.keras\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 0.3971 - mae: 0.4557 - rmse: 0.6301 - val_loss: 0.3256 - val_mae: 0.4051 - val_rmse: 0.5706 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.4005 - mae: 0.4556 - rmse: 0.6328\n",
      "Epoch 14: val_loss improved from 0.32562 to 0.31349, saving model to training_logs/checkpoints/california_housing/model_14-0.3135.keras\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 0.4005 - mae: 0.4556 - rmse: 0.6328 - val_loss: 0.3135 - val_mae: 0.3931 - val_rmse: 0.5599 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m411/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3927 - mae: 0.4506 - rmse: 0.6264\n",
      "Epoch 15: val_loss improved from 0.31349 to 0.29421, saving model to training_logs/checkpoints/california_housing/model_15-0.2942.keras\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 0.3927 - mae: 0.4505 - rmse: 0.6264 - val_loss: 0.2942 - val_mae: 0.3813 - val_rmse: 0.5424 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m411/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.4042 - mae: 0.4537 - rmse: 0.6356\n",
      "Epoch 16: val_loss did not improve from 0.29421\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 0.4042 - mae: 0.4537 - rmse: 0.6356 - val_loss: 0.3586 - val_mae: 0.4276 - val_rmse: 0.5988 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3854 - mae: 0.4449 - rmse: 0.6208\n",
      "Epoch 17: val_loss did not improve from 0.29421\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 0.3854 - mae: 0.4449 - rmse: 0.6208 - val_loss: 0.3153 - val_mae: 0.4134 - val_rmse: 0.5615 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m410/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3938 - mae: 0.4505 - rmse: 0.6274\n",
      "Epoch 18: val_loss did not improve from 0.29421\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 0.3938 - mae: 0.4505 - rmse: 0.6274 - val_loss: 0.3179 - val_mae: 0.4011 - val_rmse: 0.5638 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m411/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3860 - mae: 0.4439 - rmse: 0.6210\n",
      "Epoch 19: val_loss did not improve from 0.29421\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 0.3860 - mae: 0.4439 - rmse: 0.6210 - val_loss: 0.3171 - val_mae: 0.4099 - val_rmse: 0.5631 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m412/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.4039 - mae: 0.4506 - rmse: 0.6346\n",
      "Epoch 20: val_loss did not improve from 0.29421\n",
      "\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 0.4039 - mae: 0.4506 - rmse: 0.6345 - val_loss: 0.3403 - val_mae: 0.4349 - val_rmse: 0.5834 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m410/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3685 - mae: 0.4342 - rmse: 0.6069\n",
      "Epoch 21: val_loss did not improve from 0.29421\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 0.3686 - mae: 0.4342 - rmse: 0.6069 - val_loss: 0.2991 - val_mae: 0.3920 - val_rmse: 0.5469 - learning_rate: 2.0000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3676 - mae: 0.4344 - rmse: 0.6062\n",
      "Epoch 22: val_loss did not improve from 0.29421\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 0.3676 - mae: 0.4344 - rmse: 0.6062 - val_loss: 0.3031 - val_mae: 0.3944 - val_rmse: 0.5506 - learning_rate: 2.0000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3568 - mae: 0.4239 - rmse: 0.5972\n",
      "Epoch 23: val_loss did not improve from 0.29421\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 0.3568 - mae: 0.4239 - rmse: 0.5972 - val_loss: 0.3207 - val_mae: 0.4095 - val_rmse: 0.5663 - learning_rate: 2.0000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m411/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3631 - mae: 0.4340 - rmse: 0.6025\n",
      "Epoch 24: val_loss did not improve from 0.29421\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 0.3631 - mae: 0.4340 - rmse: 0.6025 - val_loss: 0.3165 - val_mae: 0.4017 - val_rmse: 0.5626 - learning_rate: 2.0000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m411/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3735 - mae: 0.4371 - rmse: 0.6111\n",
      "Epoch 25: val_loss did not improve from 0.29421\n",
      "\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 0.3735 - mae: 0.4371 - rmse: 0.6111 - val_loss: 0.2951 - val_mae: 0.3875 - val_rmse: 0.5433 - learning_rate: 2.0000e-04\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f186abe-f6f7-45ca-b284-f0572ea792a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-5a1990add738b83b\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-5a1990add738b83b\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Launch TensorBoard\n",
    "%tensorboard --logdir training_logs/logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96f2eea-a47b-4d82-8d26-be01dce4025b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Training Plots\n",
    "def save_training_plots(history, save_dir=\"training_logs/plots\"):\n",
    "    \"\"\"\n",
    "    Save training history plots\n",
    "    \n",
    "    Args:\n",
    "        history: Keras history object containing training metrics\n",
    "        save_dir: Directory to save the plot files\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    if not history or not hasattr(history, 'history'):\n",
    "        raise ValueError(\"Invalid history object\")\n",
    "        \n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # Plot loss\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    if 'val_loss' in history.history:\n",
    "        plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(save_dir, 'loss_plot.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # Plot metrics\n",
    "    for metric in ['mae', 'rmse']:\n",
    "        if metric in history.history:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(history.history[metric], label=f'Training {metric.upper()}')\n",
    "            val_metric = f'val_{metric}'\n",
    "            if val_metric in history.history:\n",
    "                plt.plot(history.history[val_metric], \n",
    "                        label=f'Validation {metric.upper()}')\n",
    "            plt.title(f'Model {metric.upper()}')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel(metric.upper())\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.savefig(os.path.join(save_dir, f'{metric}_plot.png'))\n",
    "            plt.close()\n",
    "\n",
    "# Use after training\n",
    "save_training_plots(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF-GPU:2.16",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
