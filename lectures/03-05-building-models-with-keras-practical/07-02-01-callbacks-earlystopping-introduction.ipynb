{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "297156c1-7deb-4c1d-b601-7a156476a408",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center;font-size:22pt; font-weight:bold;color:white;border:solid black 1.5pt;background-color:#1e7263;\">\n",
    "    Understanding Model History Object: Classification Task\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "131fa24a-96cf-4cc5-a2a7-945b355942c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================= #\n",
    "# Course: Deep Learning Complete Course (CS-501)\n",
    "# Author: Dr. Saad Laouadi\n",
    "# Institution: Quant Coding Versity Academy\n",
    "# Date: December 25, 2024\n",
    "#\n",
    "# ==========================================================\n",
    "# Lesson: Understanding Model History Object in Keras\n",
    "#         Analyzing and Visualizing Training Progress\n",
    "# ==========================================================\n",
    "# ## Learning Objectives\n",
    "# This guide will enable you to:\n",
    "# 1. Access and interpret the model.fit() history object\n",
    "# 2. Extract and analyze training metrics over epochs\n",
    "# 3. Visualize training and validation metrics\n",
    "# 4. Identify optimal training epochs and model performance\n",
    "# 5. Detect overfitting through history analysis\n",
    "# =======================================================================\n",
    "#          Copyright © Dr. Saad Laouadi 2024\n",
    "# ======================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c26ca844-8301-46b7-89da-e2dca2248ec4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================\n",
      "Author: Dr. Saad Laouadi\n",
      "\n",
      "Last updated: 2024-12-30\n",
      "\n",
      "Compiler    : Clang 14.0.6 \n",
      "OS          : Darwin\n",
      "Release     : 24.1.0\n",
      "Machine     : arm64\n",
      "Processor   : arm\n",
      "CPU cores   : 16\n",
      "Architecture: 64bit\n",
      "\n",
      "========================================================================\n",
      "Imported Packages and Their Versions:\n",
      "========================================================================\n",
      "tensorflow: 2.16.2\n",
      "sklearn   : 1.5.1\n",
      "matplotlib: 3.9.2\n",
      "pandas    : 2.2.2\n",
      "keras     : 3.6.0\n",
      "seaborn   : 0.13.2\n",
      "numpy     : 1.26.4\n",
      "\n",
      "========================================================================\n"
     ]
    }
   ],
   "source": [
    "# ==================================================== #\n",
    "#        Load Required Libraries\n",
    "# ==================================================== #\n",
    "\n",
    "import os  \n",
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "# Disable Metal API Validation\n",
    "os.environ[\"METAL_DEVICE_WRAPPER_TYPE\"] = \"0\"  \n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# import tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Set styling for better visualization\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"=\"*72)\n",
    "\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Dr. Saad Laouadi\" -u -d -m\n",
    "\n",
    "print(\"=\"*72)\n",
    "print(\"Imported Packages and Their Versions:\")\n",
    "print(\"=\"*72)\n",
    "\n",
    "%watermark -iv\n",
    "print(\"=\"*72)\n",
    "\n",
    "# Global Config\n",
    "RANDOM_STATE = 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44fbc7b1-be5c-496b-a1b4-2bd697016faf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cleanup_directory(directory_path):\n",
    "    \"\"\"\n",
    "    Deletes the specified directory and all its contents.\n",
    "\n",
    "    Args:\n",
    "        directory_path (str): Path to the directory to delete.\n",
    "    \"\"\"\n",
    "    if os.path.exists(directory_path) and os.path.isdir(directory_path):\n",
    "        shutil.rmtree(directory_path)\n",
    "        print(f\"Directory '{os.path.basename(directory_path)}' deleted successfully.\")\n",
    "    else:\n",
    "        print(f\"Directory '{os.path.basename(directory_path)}' does not exist or is not a directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd874e58-88b9-4010-8c71-9cf1ad67d093",
   "metadata": {},
   "source": [
    "### ML Model Raodmap\n",
    "1. Read the data\n",
    "2. Explore the data\n",
    "\n",
    "3. Processing\n",
    "    - Numerical features (scaling)\n",
    "    \n",
    "4. Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf2f3b2e-20e1-4021-ab07-7bbd6d64baed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================== #\n",
    "#        Implementing ModelCheckpoint \n",
    "#        Callback with Synthetic data\n",
    "# ==================================================== #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3fe3e2a9-4e57-44db-be62-328064c355d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic dataset (same as before)\n",
    "def create_synthetic_data(n_samples=1000, random_state = 0):\n",
    "    X, y = make_classification(\n",
    "        n_samples=n_samples,\n",
    "        n_features=20,\n",
    "        n_informative=15,\n",
    "        n_redundant=5,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    y = tf.keras.utils.to_categorical(y)\n",
    "    \n",
    "    return train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "\n",
    "# Create a simple neural network model (same as before)\n",
    "def create_model(input_shape):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape = input_shape),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dense(2, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d04a982c-97bb-47c8-ab48-09a730d305a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5971 - loss: 0.7338 - val_accuracy: 0.7500 - val_loss: 0.5350\n",
      "Epoch 2/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7660 - loss: 0.4692 - val_accuracy: 0.8000 - val_loss: 0.4316\n",
      "Epoch 3/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8503 - loss: 0.3463 - val_accuracy: 0.8625 - val_loss: 0.3693\n",
      "Epoch 4/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8914 - loss: 0.2717 - val_accuracy: 0.8500 - val_loss: 0.3319\n",
      "Epoch 5/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9123 - loss: 0.2296 - val_accuracy: 0.8687 - val_loss: 0.3023\n",
      "Epoch 6/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9205 - loss: 0.2037 - val_accuracy: 0.8750 - val_loss: 0.2958\n",
      "Epoch 7/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9493 - loss: 0.1599 - val_accuracy: 0.9187 - val_loss: 0.2522\n",
      "Epoch 8/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9542 - loss: 0.1527 - val_accuracy: 0.8813 - val_loss: 0.2680\n",
      "Epoch 9/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9607 - loss: 0.1411 - val_accuracy: 0.9375 - val_loss: 0.2194\n",
      "Epoch 10/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9640 - loss: 0.1237 - val_accuracy: 0.9187 - val_loss: 0.2360\n",
      "Epoch 11/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9583 - loss: 0.1219 - val_accuracy: 0.9312 - val_loss: 0.2151\n",
      "Epoch 12/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9705 - loss: 0.1164 - val_accuracy: 0.9125 - val_loss: 0.2193\n",
      "Epoch 13/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9770 - loss: 0.1000 - val_accuracy: 0.9125 - val_loss: 0.2134\n",
      "Epoch 14/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9717 - loss: 0.0879 - val_accuracy: 0.9187 - val_loss: 0.2021\n",
      "Epoch 15/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9766 - loss: 0.0848 - val_accuracy: 0.9125 - val_loss: 0.2027\n",
      "Epoch 16/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9804 - loss: 0.0714 - val_accuracy: 0.9187 - val_loss: 0.1961\n",
      "Epoch 17/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9871 - loss: 0.0697 - val_accuracy: 0.9187 - val_loss: 0.2090\n",
      "Epoch 18/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9936 - loss: 0.0578 - val_accuracy: 0.9187 - val_loss: 0.2130\n",
      "Epoch 19/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9840 - loss: 0.0607 - val_accuracy: 0.9187 - val_loss: 0.1985\n",
      "Epoch 20/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9979 - loss: 0.0521 - val_accuracy: 0.9250 - val_loss: 0.1918\n",
      "Epoch 21/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9893 - loss: 0.0619 - val_accuracy: 0.9187 - val_loss: 0.2074\n",
      "Epoch 22/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9934 - loss: 0.0397 - val_accuracy: 0.9250 - val_loss: 0.1976\n",
      "Epoch 23/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9964 - loss: 0.0398 - val_accuracy: 0.9187 - val_loss: 0.2007\n",
      "Epoch 24/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9896 - loss: 0.0422 - val_accuracy: 0.9250 - val_loss: 0.1950\n",
      "Epoch 25/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9993 - loss: 0.0273 - val_accuracy: 0.9250 - val_loss: 0.1980\n",
      "Epoch 25: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Main training function with early stopping\n",
    "\n",
    "# Generate synthetic data\n",
    "X_train, X_test, y_train, y_test = create_synthetic_data()\n",
    "\n",
    "# Create model\n",
    "model = create_model((X_train.shape[1],))\n",
    "\n",
    "# Create checkpoint directory if it doesn't exist\n",
    "checkpoint_dir = 'model_checkpoints'\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "\n",
    "# Define different types of EarlyStopping callbacks\n",
    "\n",
    "# 1. Basic early stopping monitoring validation loss\n",
    "early_stopping_basic = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train the model with early stopping callback\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=100,  # Set a high number of epochs, early stopping will prevent overfitting\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[\n",
    "        early_stopping_basic\n",
    "    ],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9fdeea0-3beb-4076-aa5d-b6d59c3ebb88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0156 - val_accuracy: 0.9375 - val_loss: 0.1971\n",
      "Epoch 2/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0159 - val_accuracy: 0.9375 - val_loss: 0.1971\n",
      "Epoch 3/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0140 - val_accuracy: 0.9375 - val_loss: 0.2033\n",
      "Epoch 4/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0113 - val_accuracy: 0.9375 - val_loss: 0.1992\n",
      "Epoch 5/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0110 - val_accuracy: 0.9375 - val_loss: 0.2000\n",
      "Epoch 6/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0125 - val_accuracy: 0.9375 - val_loss: 0.2013\n",
      "Epoch 7/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0102 - val_accuracy: 0.9375 - val_loss: 0.2014\n",
      "Epoch 7: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n"
     ]
    }
   ],
   "source": [
    "# 2. Early stopping with restoration of best weights\n",
    "early_stopping_with_restore = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Train the model with early stopping callback\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=100,  # Set a high number of epochs, early stopping will prevent overfitting\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[\n",
    "        early_stopping_with_restore\n",
    "    ],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9d3b567-efb6-48b7-99dd-e68cf8c424bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0149 - val_accuracy: 0.9375 - val_loss: 0.2007\n",
      "Epoch 2/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0118 - val_accuracy: 0.9438 - val_loss: 0.2012\n",
      "Epoch 3/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0143 - val_accuracy: 0.9375 - val_loss: 0.2003\n",
      "Epoch 4/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0103 - val_accuracy: 0.9375 - val_loss: 0.1996\n",
      "Epoch 5/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0095 - val_accuracy: 0.9375 - val_loss: 0.2006\n",
      "Epoch 6/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0112 - val_accuracy: 0.9375 - val_loss: 0.2023\n",
      "Epoch 6: early stopping\n"
     ]
    }
   ],
   "source": [
    "# 3. Early stopping with minimum change threshold\n",
    "early_stopping_min_delta = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    min_delta=0.01,  # Minimum change to qualify as an improvement\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "# Train the model with early stopping callback\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=100,  \n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[\n",
    "        early_stopping_min_delta\n",
    "    ],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d78df4b9-4b54-4326-bb33-a041bbaabb91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0104 - val_accuracy: 0.9375 - val_loss: 0.2056\n",
      "Epoch 2/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0080 - val_accuracy: 0.9375 - val_loss: 0.2026\n",
      "Epoch 3/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0081 - val_accuracy: 0.9375 - val_loss: 0.2042\n",
      "Epoch 4/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0065 - val_accuracy: 0.9375 - val_loss: 0.2017\n",
      "Epoch 5/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0065 - val_accuracy: 0.9375 - val_loss: 0.2048\n",
      "Epoch 6/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0074 - val_accuracy: 0.9375 - val_loss: 0.2035\n",
      "Epoch 6: early stopping\n"
     ]
    }
   ],
   "source": [
    "# 4. Early stopping monitoring validation accuracy\n",
    "early_stopping_accuracy = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',  # For accuracy, we want to maximize\n",
    "    patience=5,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train the model with early stopping callback\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=100,  # Set a high number of epochs, early stopping will prevent overfitting\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[\n",
    "        early_stopping_accuracy\n",
    "    ],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b279d760-50c5-4ee5-bcb2-23f078542b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m14/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0060\n",
      "Epoch 1: val_loss improved from inf to 0.20224, saving model to model_checkpoints/best_model_early_stopping.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0060 - val_accuracy: 0.9375 - val_loss: 0.2022\n",
      "Epoch 2/100\n",
      "\u001b[1m15/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0053\n",
      "Epoch 2: val_loss did not improve from 0.20224\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 0.9375 - val_loss: 0.2045\n",
      "Epoch 3/100\n",
      "\u001b[1m15/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0063\n",
      "Epoch 3: val_loss did not improve from 0.20224\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0061 - val_accuracy: 0.9375 - val_loss: 0.2070\n",
      "Epoch 4/100\n",
      "\u001b[1m15/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0049\n",
      "Epoch 4: val_loss did not improve from 0.20224\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 0.9375 - val_loss: 0.2082\n",
      "Epoch 5/100\n",
      "\u001b[1m15/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0043\n",
      "Epoch 5: val_loss did not improve from 0.20224\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0045 - val_accuracy: 0.9438 - val_loss: 0.2038\n",
      "Epoch 5: early stopping\n",
      "Epoch 5: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "Epoch 5: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Combine with ModelCheckpoint for best practice\n",
    "checkpoint_best = ModelCheckpoint(\n",
    "    filepath=os.path.join(checkpoint_dir, 'best_model_early_stopping.keras'),\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train the model with callbacks\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=100,  # Set a high number of epochs, early stopping will prevent overfitting\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[\n",
    "        early_stopping_basic,\n",
    "        early_stopping_with_restore,\n",
    "        early_stopping_min_delta,\n",
    "        early_stopping_accuracy,\n",
    "        checkpoint_best\n",
    "    ],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5728c592-0e18-4047-b719-66781c23f04b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scenario 1: Basic Early Stopping\n",
      "Epoch 1/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6752 - loss: 0.7237 - val_accuracy: 0.8062 - val_loss: 0.4603\n",
      "Epoch 2/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8016 - loss: 0.4364 - val_accuracy: 0.8687 - val_loss: 0.3593\n",
      "Epoch 3/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8617 - loss: 0.3414 - val_accuracy: 0.8687 - val_loss: 0.3299\n",
      "Epoch 4/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8990 - loss: 0.2680 - val_accuracy: 0.8875 - val_loss: 0.3057\n",
      "Epoch 5/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9033 - loss: 0.2518 - val_accuracy: 0.8875 - val_loss: 0.2863\n",
      "Epoch 6/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9288 - loss: 0.2184 - val_accuracy: 0.8938 - val_loss: 0.2799\n",
      "Epoch 7/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9291 - loss: 0.1920 - val_accuracy: 0.9250 - val_loss: 0.2532\n",
      "Epoch 8/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9429 - loss: 0.1729 - val_accuracy: 0.9312 - val_loss: 0.2488\n",
      "Epoch 9/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9452 - loss: 0.1512 - val_accuracy: 0.9312 - val_loss: 0.2422\n",
      "Epoch 10/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9546 - loss: 0.1394 - val_accuracy: 0.9375 - val_loss: 0.2385\n",
      "Epoch 11/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9605 - loss: 0.1326 - val_accuracy: 0.9312 - val_loss: 0.2296\n",
      "Epoch 12/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9594 - loss: 0.1172 - val_accuracy: 0.9250 - val_loss: 0.2270\n",
      "Epoch 13/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9701 - loss: 0.1024 - val_accuracy: 0.9438 - val_loss: 0.2195\n",
      "Epoch 14/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9732 - loss: 0.0994 - val_accuracy: 0.9312 - val_loss: 0.2105\n",
      "Epoch 15/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9868 - loss: 0.0889 - val_accuracy: 0.9375 - val_loss: 0.2147\n",
      "Epoch 16/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9820 - loss: 0.0764 - val_accuracy: 0.9312 - val_loss: 0.2106\n",
      "Epoch 17/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9865 - loss: 0.0666 - val_accuracy: 0.9312 - val_loss: 0.2108\n",
      "Epoch 17: early stopping\n",
      "\n",
      "Scenario 2: Early Stopping with Baseline Target\n",
      "Epoch 1/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5433 - loss: 0.7197 - val_accuracy: 0.6750 - val_loss: 0.5882\n",
      "Epoch 2/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7431 - loss: 0.5078 - val_accuracy: 0.8313 - val_loss: 0.4661\n",
      "Epoch 3/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8587 - loss: 0.3642 - val_accuracy: 0.8562 - val_loss: 0.3919\n",
      "Epoch 4/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8856 - loss: 0.2953 - val_accuracy: 0.8562 - val_loss: 0.3462\n",
      "Epoch 5/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9310 - loss: 0.2394 - val_accuracy: 0.8750 - val_loss: 0.3071\n",
      "Epoch 6/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9479 - loss: 0.1896 - val_accuracy: 0.8875 - val_loss: 0.2877\n",
      "Epoch 7/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9628 - loss: 0.1665 - val_accuracy: 0.8875 - val_loss: 0.2599\n",
      "Epoch 8/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9670 - loss: 0.1358 - val_accuracy: 0.9125 - val_loss: 0.2488\n",
      "Epoch 9/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9474 - loss: 0.1526 - val_accuracy: 0.9125 - val_loss: 0.2361\n",
      "Epoch 10/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9692 - loss: 0.1225 - val_accuracy: 0.9312 - val_loss: 0.2220\n",
      "Epoch 11/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9803 - loss: 0.0956 - val_accuracy: 0.9312 - val_loss: 0.2115\n",
      "Epoch 12/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9812 - loss: 0.0854 - val_accuracy: 0.9438 - val_loss: 0.2009\n",
      "Epoch 13/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9825 - loss: 0.0846 - val_accuracy: 0.9438 - val_loss: 0.1981\n",
      "Epoch 14/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9839 - loss: 0.0764 - val_accuracy: 0.9500 - val_loss: 0.1940\n",
      "Epoch 15/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9883 - loss: 0.0700 - val_accuracy: 0.9625 - val_loss: 0.1898\n",
      "Epoch 16/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9888 - loss: 0.0565 - val_accuracy: 0.9625 - val_loss: 0.1834\n",
      "Epoch 17/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9913 - loss: 0.0527 - val_accuracy: 0.9688 - val_loss: 0.1775\n",
      "Epoch 18/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9898 - loss: 0.0514 - val_accuracy: 0.9625 - val_loss: 0.1830\n",
      "Epoch 19/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9973 - loss: 0.0409 - val_accuracy: 0.9625 - val_loss: 0.1760\n",
      "Epoch 20/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9956 - loss: 0.0384 - val_accuracy: 0.9625 - val_loss: 0.1737\n",
      "Epoch 21/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9939 - loss: 0.0358 - val_accuracy: 0.9625 - val_loss: 0.1700\n",
      "Epoch 22/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9954 - loss: 0.0297 - val_accuracy: 0.9625 - val_loss: 0.1706\n",
      "Epoch 23/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9964 - loss: 0.0323 - val_accuracy: 0.9625 - val_loss: 0.1717\n",
      "Epoch 24/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9975 - loss: 0.0259 - val_accuracy: 0.9625 - val_loss: 0.1692\n",
      "Epoch 25/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9977 - loss: 0.0258 - val_accuracy: 0.9625 - val_loss: 0.1689\n",
      "Epoch 26/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9969 - loss: 0.0239 - val_accuracy: 0.9625 - val_loss: 0.1656\n",
      "Epoch 27/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0240 - val_accuracy: 0.9688 - val_loss: 0.1697\n",
      "Epoch 28/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 0.0181 - val_accuracy: 0.9688 - val_loss: 0.1668\n",
      "Epoch 29/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0182 - val_accuracy: 0.9625 - val_loss: 0.1695\n",
      "Epoch 29: early stopping\n",
      "\n",
      "Scenario 3: Early Stopping with Best Weights Restoration\n",
      "Epoch 1/100\n",
      "\u001b[1m14/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4729 - loss: 1.4101 \n",
      "Epoch 1: val_loss improved from inf to 0.49063, saving model to model_checkpoints/scenario3_best_model.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5081 - loss: 1.2510 - val_accuracy: 0.7688 - val_loss: 0.4906\n",
      "Epoch 2/100\n",
      "\u001b[1m14/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7826 - loss: 0.4713\n",
      "Epoch 2: val_loss improved from 0.49063 to 0.31341, saving model to model_checkpoints/scenario3_best_model.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7875 - loss: 0.4632 - val_accuracy: 0.8750 - val_loss: 0.3134\n",
      "Epoch 3/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9081 - loss: 0.2942\n",
      "Epoch 3: val_loss improved from 0.31341 to 0.28628, saving model to model_checkpoints/scenario3_best_model.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9070 - loss: 0.2948 - val_accuracy: 0.9000 - val_loss: 0.2863\n",
      "Epoch 4/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8981 - loss: 0.2630\n",
      "Epoch 4: val_loss improved from 0.28628 to 0.27477, saving model to model_checkpoints/scenario3_best_model.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8987 - loss: 0.2624 - val_accuracy: 0.8938 - val_loss: 0.2748\n",
      "Epoch 5/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9202 - loss: 0.2198\n",
      "Epoch 5: val_loss improved from 0.27477 to 0.24137, saving model to model_checkpoints/scenario3_best_model.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9204 - loss: 0.2199 - val_accuracy: 0.9125 - val_loss: 0.2414\n",
      "Epoch 6/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9314 - loss: 0.1966\n",
      "Epoch 6: val_loss improved from 0.24137 to 0.23273, saving model to model_checkpoints/scenario3_best_model.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9314 - loss: 0.1966 - val_accuracy: 0.9250 - val_loss: 0.2327\n",
      "Epoch 7/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9422 - loss: 0.1675\n",
      "Epoch 7: val_loss improved from 0.23273 to 0.22450, saving model to model_checkpoints/scenario3_best_model.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9419 - loss: 0.1680 - val_accuracy: 0.9187 - val_loss: 0.2245\n",
      "Epoch 8/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9379 - loss: 0.1560\n",
      "Epoch 8: val_loss improved from 0.22450 to 0.21822, saving model to model_checkpoints/scenario3_best_model.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9382 - loss: 0.1560 - val_accuracy: 0.9312 - val_loss: 0.2182\n",
      "Epoch 9/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9500 - loss: 0.1563\n",
      "Epoch 9: val_loss did not improve from 0.21822\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9502 - loss: 0.1549 - val_accuracy: 0.9187 - val_loss: 0.2222\n",
      "Epoch 10/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9636 - loss: 0.1348\n",
      "Epoch 10: val_loss improved from 0.21822 to 0.20641, saving model to model_checkpoints/scenario3_best_model.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9633 - loss: 0.1346 - val_accuracy: 0.9375 - val_loss: 0.2064\n",
      "Epoch 11/100\n",
      "\u001b[1m15/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9620 - loss: 0.1211\n",
      "Epoch 11: val_loss did not improve from 0.20641\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9632 - loss: 0.1201 - val_accuracy: 0.9250 - val_loss: 0.2160\n",
      "Epoch 12/100\n",
      "\u001b[1m15/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9583 - loss: 0.1151\n",
      "Epoch 12: val_loss improved from 0.20641 to 0.19779, saving model to model_checkpoints/scenario3_best_model.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9605 - loss: 0.1137 - val_accuracy: 0.9375 - val_loss: 0.1978\n",
      "Epoch 13/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9827 - loss: 0.0815\n",
      "Epoch 13: val_loss did not improve from 0.19779\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9812 - loss: 0.0832 - val_accuracy: 0.9312 - val_loss: 0.2025\n",
      "Epoch 14/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9623 - loss: 0.1025\n",
      "Epoch 14: val_loss improved from 0.19779 to 0.19524, saving model to model_checkpoints/scenario3_best_model.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9632 - loss: 0.1015 - val_accuracy: 0.9312 - val_loss: 0.1952\n",
      "Epoch 15/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9663 - loss: 0.0897\n",
      "Epoch 15: val_loss did not improve from 0.19524\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9665 - loss: 0.0894 - val_accuracy: 0.9250 - val_loss: 0.2008\n",
      "Epoch 16/100\n",
      "\u001b[1m15/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9830 - loss: 0.0663\n",
      "Epoch 16: val_loss improved from 0.19524 to 0.18806, saving model to model_checkpoints/scenario3_best_model.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9814 - loss: 0.0693 - val_accuracy: 0.9312 - val_loss: 0.1881\n",
      "Epoch 17/100\n",
      "\u001b[1m14/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9910 - loss: 0.0620\n",
      "Epoch 17: val_loss improved from 0.18806 to 0.18622, saving model to model_checkpoints/scenario3_best_model.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9874 - loss: 0.0659 - val_accuracy: 0.9187 - val_loss: 0.1862\n",
      "Epoch 18/100\n",
      "\u001b[1m15/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9739 - loss: 0.0849\n",
      "Epoch 18: val_loss did not improve from 0.18622\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9748 - loss: 0.0805 - val_accuracy: 0.9312 - val_loss: 0.2079\n",
      "Epoch 19/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9871 - loss: 0.0634\n",
      "Epoch 19: val_loss improved from 0.18622 to 0.18526, saving model to model_checkpoints/scenario3_best_model.keras\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9872 - loss: 0.0634 - val_accuracy: 0.9250 - val_loss: 0.1853\n",
      "Epoch 20/100\n",
      "\u001b[1m19/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9948 - loss: 0.0507\n",
      "Epoch 20: val_loss did not improve from 0.18526\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9946 - loss: 0.0511 - val_accuracy: 0.9312 - val_loss: 0.2002\n",
      "Epoch 21/100\n",
      "\u001b[1m14/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9968 - loss: 0.0429\n",
      "Epoch 21: val_loss did not improve from 0.18526\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9951 - loss: 0.0459 - val_accuracy: 0.9250 - val_loss: 0.1911\n",
      "Epoch 22/100\n",
      "\u001b[1m15/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9935 - loss: 0.0504\n",
      "Epoch 22: val_loss did not improve from 0.18526\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9937 - loss: 0.0496 - val_accuracy: 0.9187 - val_loss: 0.2094\n",
      "Epoch 23/100\n",
      "\u001b[1m14/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9898 - loss: 0.0506\n",
      "Epoch 23: val_loss did not improve from 0.18526\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9913 - loss: 0.0485 - val_accuracy: 0.9187 - val_loss: 0.1875\n",
      "Epoch 24/100\n",
      "\u001b[1m15/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9919 - loss: 0.0409\n",
      "Epoch 24: val_loss did not improve from 0.18526\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9928 - loss: 0.0410 - val_accuracy: 0.9187 - val_loss: 0.2038\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "\n",
      "Scenario: basic\n",
      "Best validation loss: 0.2105\n",
      "Training stopped after 17 epochs\n",
      "\n",
      "Scenario: baseline\n",
      "Best validation loss: 0.1656\n",
      "Training stopped after 29 epochs\n",
      "\n",
      "Scenario: restore_best\n",
      "Best validation loss: 0.1853\n",
      "Training stopped after 24 epochs\n"
     ]
    }
   ],
   "source": [
    "def demonstrate_early_stopping_scenarios(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Demonstrates different early stopping scenarios and their effects\n",
    "    \"\"\"\n",
    "    # Create checkpoint directory\n",
    "    checkpoint_dir = 'model_checkpoints'\n",
    "    if not os.path.exists(checkpoint_dir):\n",
    "        os.makedirs(checkpoint_dir)\n",
    "\n",
    "    # Scenario 1: Basic early stopping\n",
    "    print(\"\\nScenario 1: Basic Early Stopping\")\n",
    "    model1 = create_model((X_train.shape[1],))\n",
    "    early_stopping1 = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=3,\n",
    "        verbose=1\n",
    "    )\n",
    "    history1 = model1.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        validation_split=0.2,\n",
    "        callbacks=[early_stopping1],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Scenario 2: Early stopping with baseline\n",
    "    print(\"\\nScenario 2: Early Stopping with Baseline Target\")\n",
    "    model2 = create_model((X_train.shape[1],))\n",
    "    early_stopping2 = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        baseline=0.3,  # Stop if we achieve this target loss\n",
    "        patience=3,\n",
    "        verbose=1\n",
    "    )\n",
    "    history2 = model2.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        validation_split=0.2,\n",
    "        callbacks=[early_stopping2],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Scenario 3: Early stopping with best weights restoration\n",
    "    print(\"\\nScenario 3: Early Stopping with Best Weights Restoration\")\n",
    "    model3 = create_model((X_train.shape[1],))\n",
    "    early_stopping3 = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    checkpoint3 = ModelCheckpoint(\n",
    "        filepath=os.path.join(checkpoint_dir, 'scenario3_best_model.keras'),\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    history3 = model3.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        validation_split=0.2,\n",
    "        callbacks=[early_stopping3, checkpoint3],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        'basic': (model1, history1),\n",
    "        'baseline': (model2, history2),\n",
    "        'restore_best': (model3, history3)\n",
    "    }\n",
    "\n",
    "\n",
    "# Run different scenarios\n",
    "results = demonstrate_early_stopping_scenarios(X_train, y_train, X_test, y_test)\n",
    "\n",
    "# You can now compare the results\n",
    "for scenario, (model, history) in results.items():\n",
    "    val_loss = min(history.history['val_loss'])\n",
    "    epochs_run = len(history.history['loss'])\n",
    "    print(f\"\\nScenario: {scenario}\")\n",
    "    print(f\"Best validation loss: {val_loss:.4f}\")\n",
    "    print(f\"Training stopped after {epochs_run} epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98210a6e-1667-442f-9f7b-1a7b179f7e6a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'model_checkpoints' deleted successfully.\n"
     ]
    }
   ],
   "source": [
    "# Cleanup \n",
    "cleanup_directory(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac67ae7-e714-4600-9a3a-52cf5cfae921",
   "metadata": {},
   "source": [
    "## Key differences from the ModelCheckpoint example:\n",
    "\n",
    " - EarlyStopping is focused on preventing overfitting by monitoring training metrics\n",
    " - It includes parameters like patience and min_delta for fine-tuning stopping conditions\n",
    " - The restore_best_weights option can automatically restore the model to its best state\n",
    " - It can monitor different metrics (loss, accuracy) with different modes (min, max)\n",
    " - We set a higher number of epochs (100) since early stopping will prevent unnecessary training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e69135-d386-495c-b6b5-9779d14b673c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF-GPU:2.16",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
