{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "297156c1-7deb-4c1d-b601-7a156476a408",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center;font-size:22pt; font-weight:bold;color:white;border:solid black 1.5pt;background-color:#1e7263;\">\n",
    "    Model Capacity in Deep Learning: A Comprehensive Guide\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "131fa24a-96cf-4cc5-a2a7-945b355942c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================= #\n",
    "# Course: Deep Learning Complete Course (CS-501)\n",
    "# Author: Dr. Saad Laouadi\n",
    "# Institution: Quant Coding Versity Academy\n",
    "#\n",
    "# ==========================================================\n",
    "# Lesson: Understand Model Capacity in Deep Learning\n",
    "#         \n",
    "# ==========================================================\n",
    "# Learning Objectives:\n",
    "# ===================\n",
    "# 1. The Essence of Model Capacity in Deep learning\n",
    "# 2. Bias-variance trade-off\n",
    "# 3. Practical guidelines for model capacity\n",
    "# =======================================================================\n",
    "#          Copyright Â© Dr. Saad Laouadi 2025\n",
    "# ======================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c26ca844-8301-46b7-89da-e2dca2248ec4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================\n",
      "Author: Dr. Saad Laouadi\n",
      "\n",
      "Last updated: 2025-01-21\n",
      "\n",
      "Compiler    : Clang 14.0.6 \n",
      "OS          : Darwin\n",
      "Release     : 24.1.0\n",
      "Machine     : arm64\n",
      "Processor   : arm\n",
      "CPU cores   : 16\n",
      "Architecture: 64bit\n",
      "\n",
      "========================================================================\n",
      "Imported Packages and Their Versions:\n",
      "========================================================================\n",
      "\n",
      "========================================================================\n"
     ]
    }
   ],
   "source": [
    "# ==================================================== #\n",
    "#        Load Required Libraries\n",
    "# ==================================================== #\n",
    "\n",
    "print(\"=\"*72)\n",
    "\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Dr. Saad Laouadi\" -u -d -m\n",
    "\n",
    "print(\"=\"*72)\n",
    "print(\"Imported Packages and Their Versions:\")\n",
    "print(\"=\"*72)\n",
    "\n",
    "%watermark -iv\n",
    "print(\"=\"*72)\n",
    "\n",
    "# Global Config\n",
    "RANDOM_STATE = 101"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ac0d3c-ee83-4ca1-aa64-3457c3162925",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7185802e-61e4-4576-b0f9-eae4ee2a4a3e",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "**Model capacity** in deep learning refers to a model's ability to capture patterns and relationships in data. It's a crucial concept that directly impacts a model's ability to learn and generalize. This guide explores the various aspects of model capacity and its implications for deep learning practitioners.\n",
    "\n",
    "\n",
    "## Understanding Model Capacity\n",
    "\n",
    "### Definition and Concepts\n",
    "\n",
    "**Model capacity** represents the range of functions that a neural network can approximate. It's determined by several factors:\n",
    "\n",
    "1. **Number of Parameters**\n",
    "   - Total trainable weights and biases\n",
    "   - Directly relates to the model's ability to memorize patterns\n",
    "   - Calculated as: $\\sum \\big ( (\\text{input_size} \\times \\text{output_size}) + \\text{output_size} \\big )$ for each layer\n",
    "\n",
    "2. **Model Architecture**\n",
    "   - Network depth (number of layers)\n",
    "   - Network width (neurons per layer)\n",
    "   - Layer types and their configurations\n",
    "   - Connectivity patterns (dense, residual, etc.)\n",
    "\n",
    "3. **Effective Capacity**\n",
    "   - The subset of functions that the training algorithm can practically learn\n",
    "   - Influenced by optimization algorithm, regularization, and training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e81324-c922-4233-a1d3-6f1e269613e5",
   "metadata": {},
   "source": [
    "## The Bias-Variance Tradeoff\n",
    "\n",
    "### Understanding the Relationship\n",
    "\n",
    "$$\\text{Total Error} = \\text{Bias}^2 + \\text{Variance} + \\text{Irreducible Error}$$\n",
    "\n",
    "**Where:**\n",
    "\n",
    "- **Bias**: Error from incorrect assumptions\n",
    "- **Variance**: Error from sensitivity to training data variations\n",
    "- **Irreducible Error**: Noise in the problem itself"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01063864-e277-4f27-8ab1-2469e0c3e14c",
   "metadata": {},
   "source": [
    "### Impact of Model Capacity\n",
    "\n",
    "1. **Low Capacity Models**\n",
    "   - **High bias (underfitting)**\n",
    "   - **Low variance**\n",
    "   - **Poor training performance**\n",
    "   - **Poor generalization**\n",
    "\n",
    "2. **High Capacity Models**\n",
    "   - **Low bias**\n",
    "   - **High variance (overfitting)**\n",
    "   - **Excellent training performance**\n",
    "   - **Potentially poor generalization**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b76776-5581-4930-ac43-e1f90f11a0ed",
   "metadata": {},
   "source": [
    "## Practical Guidelines for Model Capacity\n",
    "\n",
    "### 1. Initial Capacity Estimation\n",
    "\n",
    "```python\n",
    "def estimate_model_capacity(input_size, output_size, hidden_layers):\n",
    "    \"\"\"\n",
    "    Estimate model capacity for a basic feedforward network\n",
    "    \"\"\"\n",
    "    total_params = 0\n",
    "    prev_size = input_size\n",
    "    \n",
    "    # Calculate parameters for hidden layers\n",
    "    for neurons in hidden_layers:\n",
    "        params = (prev_size * neurons) + neurons  # weights + biases\n",
    "        total_params += params\n",
    "        prev_size = neurons\n",
    "    \n",
    "    # Output layer parameters\n",
    "    total_params += (prev_size * output_size) + output_size\n",
    "    \n",
    "    return total_params\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bc712d-6395-462d-87cf-335463181dc7",
   "metadata": {},
   "source": [
    "### 2. Capacity Management Techniques\n",
    "\n",
    "#### A. Architecture Design\n",
    "\n",
    " 1. Start with a simple architecture\n",
    " 2. Gradually increase complexity\n",
    " 3. Use standard architectures as baselines\n",
    " 4. Consider the problem complexity\n",
    "\n",
    "\n",
    "```python\n",
    "# Example of gradual capacity increase\n",
    "architectures = [\n",
    "    [64],\n",
    "    [64, 32],\n",
    "    [128, 64, 32],\n",
    "    [256, 128, 64, 32]\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8d873d-11d7-4272-94e1-bcea3e8f05c8",
   "metadata": {},
   "source": [
    "#### B. Regularization Methods\n",
    "\n",
    "1. **L1/L2 Regularization**\n",
    "   ```python\n",
    "   tf.keras.layers.Dense(\n",
    "       units=64,\n",
    "       kernel_regularizer=tf.keras.regularizers.L2(l2=0.01)\n",
    "   )\n",
    "   ```\n",
    "\n",
    "2. **Dropout**\n",
    "   ```python\n",
    "   tf.keras.layers.Dropout(rate=0.3)\n",
    "   ```\n",
    "\n",
    "3. **Early Stopping**\n",
    "   ```python\n",
    "   tf.keras.callbacks.EarlyStopping(\n",
    "       monitor='val_loss',\n",
    "       patience=10\n",
    "   )\n",
    "   ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fd3d27-ad42-41bb-b101-07343b720a21",
   "metadata": {},
   "source": [
    "## Monitoring and Adjusting Capacity\n",
    "\n",
    "### 1. Learning Curves Analysis\n",
    "\n",
    "```python\n",
    "def plot_learning_curves(history):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    # Training vs Validation Loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Training vs Validation Accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae25649-6586-4c72-8d0a-bb54ca180ce2",
   "metadata": {},
   "source": [
    "### 2. Capacity Indicators\n",
    "\n",
    "1. **Training vs Validation Performance**\n",
    "   - **Similar performance**: Appropriate capacity\n",
    "   - **Large gap**: Potential overcapacity\n",
    "   - **Both poor**: Insufficient capacity\n",
    "\n",
    "2. **Learning Speed**\n",
    "   - **Too fast**: Potential overcapacity\n",
    "   - **Too slow**: Possible undercapacity\n",
    "   - **Steady progress**: Appropriate capacity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdde89f-20cc-46a1-b718-c03af3b048df",
   "metadata": {},
   "source": [
    "## Advanced Capacity Considerations\n",
    "\n",
    "### 1. Model Compression Techniques\n",
    "\n",
    "1. **Pruning**\n",
    "   - Remove unnecessary connections\n",
    "   - Reduce effective capacity while maintaining performance\n",
    "\n",
    "2. **Quantization**\n",
    "   - Reduce numerical precision\n",
    "   - Lower memory footprint without significant performance loss\n",
    "\n",
    "3. **Knowledge Distillation**\n",
    "   - Transfer knowledge from large to small models\n",
    "   - Maintain performance with reduced capacity\n",
    "\n",
    "### 2. Dynamic Capacity Adjustment\n",
    "\n",
    "1. **Architecture Search**\n",
    "   ```python\n",
    "   def search_optimal_capacity(X, y, architectures):\n",
    "       results = []\n",
    "       for arch in architectures:\n",
    "           model = create_model(arch)\n",
    "           history = model.fit(X, y, validation_split=0.2)\n",
    "           results.append({\n",
    "               'architecture': arch,\n",
    "               'val_loss': min(history.history['val_loss'])\n",
    "           })\n",
    "       return results\n",
    "   ```\n",
    "\n",
    "2. **Adaptive Regularization**\n",
    "   - Adjust regularization strength based on validation performance\n",
    "   - Balance between capacity utilization and generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d97618-4e90-42c6-99dd-48fd843bdd82",
   "metadata": {},
   "source": [
    "## Best Practices and Guidelines\n",
    "\n",
    "### 1. General Rules of Thumb\n",
    "\n",
    "1. **Start Simple**\n",
    "   - Begin with minimal architecture\n",
    "   - Add complexity incrementally\n",
    "   - Monitor performance changes\n",
    "\n",
    "2. **Data Considerations**\n",
    "   - **More data** â Can support higher capacity\n",
    "   - **Complex patterns** â Require more capacity\n",
    "   - **Noisy data** â May need regularization\n",
    "\n",
    "3. **Problem Complexity**\n",
    "   - **Linear problems** â Simple architectures\n",
    "   - **Non-linear problems** â Deeper architectures\n",
    "   - **Sequential/temporal** â RNN-based capacity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f659ab87-6903-4b2e-a63a-40c728b62135",
   "metadata": {},
   "source": [
    "### 2. Practical Implementation Steps\n",
    "\n",
    "1. **Initial Setup**\n",
    "\n",
    "```python\n",
    "# Start with a simple model\n",
    "model = tf.keras.Sequential([\n",
    "   tf.keras.layers.Dense(64, activation='relu'),\n",
    "   tf.keras.layers.Dense(32, activation='relu'),\n",
    "   tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "```\n",
    "\n",
    "2. **Monitoring**\n",
    "\n",
    "```python\n",
    "# Monitor validation metrics\n",
    "history = model.fit(\n",
    "   X_train, y_train,\n",
    "   validation_split=0.2,\n",
    "   callbacks=[\n",
    "       tf.keras.callbacks.EarlyStopping(patience=10),\n",
    "       tf.keras.callbacks.ModelCheckpoint('best_model.h5')\n",
    "   ]\n",
    ")\n",
    "```\n",
    "\n",
    "3. **Adjustment**:\n",
    "\n",
    "```python\n",
    "# If underfitting, increase capacity\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "\n",
    "# If overfitting, add regularization\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26c8951-b98a-4766-91f9-4d6f2d5eeb45",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Model capacity is a fundamental concept in deep learning that requires careful consideration and management. Key features to take under consideration:\n",
    "\n",
    "1. **Balance is crucial**\n",
    "   - Too little capacity â Underfitting\n",
    "   - Too much capacity â Overfitting\n",
    "   - Optimal capacity â Good generalization\n",
    "\n",
    "2. **Dynamic approach**\n",
    "   - Start simple\n",
    "   - Monitor performance\n",
    "   - Adjust based on evidence\n",
    "   - Use regularization when needed\n",
    "\n",
    "3. **Consider context**\n",
    "   - Data characteristics\n",
    "   - Problem complexity\n",
    "   - Resource constraints\n",
    "   - Performance requirements\n",
    "\n",
    "> Remember that finding the right capacity is often an iterative process that requires experimentation and careful monitoring of model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffc75bf-3d6d-4d73-97d4-6f34cab2414a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF-GPU:2.16",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
