{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "297156c1-7deb-4c1d-b601-7a156476a408",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center;font-size:22pt; font-weight:bold;color:white;border:solid black 1.5pt;background-color:#1e7263;\">\n",
    "    Binary Classification with Deep Learning: Titanic Survival Prediction\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131fa24a-96cf-4cc5-a2a7-945b355942c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================= #\n",
    "# Course: Deep Learning Complete Course (CS-501)\n",
    "# Author: Dr. Saad Laouadi\n",
    "# \n",
    "#\n",
    "# ==========================================================\n",
    "# Lesson: Model Specification for Neural Network with Keras \n",
    "#         API Implementation: Classification Project\n",
    "# ==========================================================\n",
    "# ## Learning Objectives\n",
    "# This guide will enable you to:\n",
    "# 1. Specify the model architecture for classification task\n",
    "# 2. Compile the model\n",
    "# 3. Fit the classification model\n",
    "# =======================================================================\n",
    "#.          Copyright Â© Dr. Saad Laouadi 2024\n",
    "# ======================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26ca844-8301-46b7-89da-e2dca2248ec4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. Environment Setup\n",
    "# ------------------\n",
    "import os  \n",
    "from pathlib import Path\n",
    "from pprint import pprint                     # This will be used for printing dicts in a nicer format\n",
    "# Disable Metal API Validation\n",
    "os.environ[\"METAL_DEVICE_WRAPPER_TYPE\"] = \"0\"   # if you have GPU\n",
    "\n",
    "# Import necessary modules\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from layers import the Input and Dense\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "\n",
    "# Import the Sequential Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# import utils from the keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "print(\"=\"*72)\n",
    "\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Dr. Saad Laouadi\" -u -d -m\n",
    "\n",
    "print(\"=\"*72)\n",
    "print(\"Imported Packages and Their Versions:\")\n",
    "print(\"=\"*72)\n",
    "\n",
    "%watermark -iv\n",
    "print(\"=\"*72)\n",
    "\n",
    "# Configuration\n",
    "DATA_PATH = Path(\"../../datasets/classification/titanic.csv\").resolve()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb01030-b3f0-4a3c-8c8b-a662fe9a6c7d",
   "metadata": {},
   "source": [
    "## Project Overview\n",
    "\n",
    "In this hands-on project, we will develop a deep learning classification model to predict passenger survival from the historic Titanic disaster. This project serves as an excellent introduction to binary classification problems, one of the fundamental tasks in machine learning and deep learning.\n",
    "\n",
    "## Dataset Description\n",
    "We will work with the famous Titanic dataset, which contains detailed information about passengers including:\n",
    "- Demographic information (age, gender)\n",
    "- Socio-economic features (passenger class, fare)\n",
    "- Travel information (cabin, port of embarkation)\n",
    "- Family relationships (siblings/spouses aboard, parents/children aboard)\n",
    "\n",
    "Our target variable is binary: whether a passenger survived (1) or did not survive (0) the disaster.\n",
    "\n",
    "## Technical Implementation\n",
    "The project will utilize:\n",
    "- Keras Sequential model development\n",
    "- **Categorical Cross-entropy** loss function\n",
    "- **Stochastic Gradient Descent (SGD)** optimizer\n",
    "\n",
    "## Model Architecture\n",
    "We will construct a neural network with:\n",
    "- An input layer matching our feature dimensions\n",
    "- A hidden layer with ReLU activation\n",
    "- An output layer with softmax activation for binary classification\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "Through this project, you will learn:\n",
    "1. How to prepare data for binary classification\n",
    "2. Converting target variables to categorical format\n",
    "3. Designing appropriate neural network architecture\n",
    "4. Configuring loss functions and optimizers\n",
    "5. Training and evaluating classification models\n",
    "\n",
    "## Key Metrics\n",
    "We will evaluate our model using:\n",
    "- `Accuracy`: Percentage of correct predictions\n",
    "- `Loss`: Categorical cross-entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8feb99e8-9594-48f4-80f7-614e6eb37931",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ==================================================== #\n",
    "#        Load and Explore the data\n",
    "# ==================================================== #\n",
    "# Load the dataset\n",
    "data = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# Display basic information about the dataset\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afea170a-2ca1-478e-a751-8543532a68b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ==================================================== #\n",
    "#        Prepare the data for model\n",
    "# ==================================================== #\n",
    "# Separate features (predictors) from the target variable\n",
    "predictors = data.drop(columns=\"survived\").values\n",
    "predictors = predictors.astype('float64')         # Convert to float64 for numerical stability\n",
    "\n",
    "# Prepare the target variable\n",
    "target = to_categorical(data.survived)            # Convert to one-hot encoded format\n",
    "\n",
    "# Print shapes to verify the data structure\n",
    "print(f\"Features shape: {predictors.shape}\")\n",
    "print(f\"Target shape: {target.shape}\")\n",
    "print(f\"Sample of target data:\\n{target[:5, :]}\")\n",
    "\n",
    "# Get the number of input features\n",
    "n_cols = predictors.shape[1]\n",
    "print(f\"Number of input features: {n_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0deefa35-a7cf-40bf-bd4b-2617a15847b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ==================================================== #\n",
    "#        Build Model Architecture\n",
    "# ==================================================== #\n",
    "# Initialize the sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the input layer with shape matching our features\n",
    "model.add(Input(shape=(n_cols,)))\n",
    "\n",
    "# Add hidden layer with 32 neurons and ReLU activation\n",
    "model.add(Dense(32, activation='relu'))\n",
    "\n",
    "# Add output layer with 2 neurons (binary classification) and softmax activation\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Display model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e1eff3-04bd-4135-a9b7-469fbd9f6a48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ==================================================== #\n",
    "#        Train the model\n",
    "# ==================================================== #\n",
    "\n",
    "# Configure the model with optimizer, loss function, and metrics\n",
    "model.compile(\n",
    "    optimizer='sgd',                       # Stochastic Gradient Descent optimizer\n",
    "    loss='categorical_crossentropy',       # Standard loss for classification\n",
    "    metrics=['accuracy']                   # Track accuracy during training\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    predictors,                            # Input features\n",
    "    target,                                # Target variable\n",
    "    epochs=25,                             # Number of training cycles\n",
    "    batch_size=16,                         # Number of samples per gradient update\n",
    "    validation_split=0.2                   # Use 20% of data for validation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a50a1d-ebd0-41f1-a6de-533124b3a79a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF-GPU:2.16",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
