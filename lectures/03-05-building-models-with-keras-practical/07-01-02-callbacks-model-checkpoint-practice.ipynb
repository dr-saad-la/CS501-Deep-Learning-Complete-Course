{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "297156c1-7deb-4c1d-b601-7a156476a408",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center;font-size:22pt; font-weight:bold;color:white;border:solid black 1.5pt;background-color:#1e7263;\">\n",
    "    Understanding Model History Object: Classification Task\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "131fa24a-96cf-4cc5-a2a7-945b355942c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================= #\n",
    "# Course: Deep Learning Complete Course (CS-501)\n",
    "# Author: Dr. Saad Laouadi\n",
    "# Institution: Quant Coding Versity Academy\n",
    "# Date: December 25, 2024\n",
    "#\n",
    "# ==========================================================\n",
    "# Lesson: Understanding Model History Object in Keras\n",
    "#         Analyzing and Visualizing Training Progress\n",
    "# ==========================================================\n",
    "# ## Learning Objectives\n",
    "# This guide will enable you to:\n",
    "# 1. Access and interpret the model.fit() history object\n",
    "# 2. Extract and analyze training metrics over epochs\n",
    "# 3. Visualize training and validation metrics\n",
    "# 4. Identify optimal training epochs and model performance\n",
    "# 5. Detect overfitting through history analysis\n",
    "# =======================================================================\n",
    "#          Copyright © Dr. Saad Laouadi 2024\n",
    "# ======================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c26ca844-8301-46b7-89da-e2dca2248ec4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================\n",
      "Author: Dr. Saad Laouadi\n",
      "\n",
      "Last updated: 2024-12-30\n",
      "\n",
      "Compiler    : Clang 14.0.6 \n",
      "OS          : Darwin\n",
      "Release     : 24.1.0\n",
      "Machine     : arm64\n",
      "Processor   : arm\n",
      "CPU cores   : 16\n",
      "Architecture: 64bit\n",
      "\n",
      "========================================================================\n",
      "Imported Packages and Their Versions:\n",
      "========================================================================\n",
      "keras     : 3.6.0\n",
      "tensorflow: 2.16.2\n",
      "matplotlib: 3.9.2\n",
      "seaborn   : 0.13.2\n",
      "sklearn   : 1.5.1\n",
      "numpy     : 1.26.4\n",
      "pandas    : 2.2.2\n",
      "\n",
      "========================================================================\n"
     ]
    }
   ],
   "source": [
    "# ==================================================== #\n",
    "#        Load Required Libraries\n",
    "# ==================================================== #\n",
    "\n",
    "import os  \n",
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "# Disable Metal API Validation\n",
    "os.environ[\"METAL_DEVICE_WRAPPER_TYPE\"] = \"0\"  \n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.datasets import fetch_covtype\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import (\n",
    "    ModelCheckpoint, \n",
    "    EarlyStopping, \n",
    "    ReduceLROnPlateau, \n",
    "    CSVLogger\n",
    ")\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    roc_curve,\n",
    "    auc,\n",
    "    precision_recall_curve\n",
    ")\n",
    "\n",
    "\n",
    "# import tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Set styling for better visualization\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"=\"*72)\n",
    "\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Dr. Saad Laouadi\" -u -d -m\n",
    "\n",
    "print(\"=\"*72)\n",
    "print(\"Imported Packages and Their Versions:\")\n",
    "print(\"=\"*72)\n",
    "\n",
    "%watermark -iv\n",
    "print(\"=\"*72)\n",
    "\n",
    "# Global Config\n",
    "RANDOM_STATE = 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44fbc7b1-be5c-496b-a1b4-2bd697016faf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cleanup_directory(directory_path):\n",
    "    \"\"\"\n",
    "    Deletes the specified directory and all its contents.\n",
    "\n",
    "    Args:\n",
    "        directory_path (str): Path to the directory to delete.\n",
    "    \"\"\"\n",
    "    if os.path.exists(directory_path) and os.path.isdir(directory_path):\n",
    "        shutil.rmtree(directory_path)\n",
    "        print(f\"Directory '{os.path.basename(directory_path)}' deleted successfully.\")\n",
    "    else:\n",
    "        print(f\"Directory '{os.path.basename(directory_path)}' does not exist or is not a directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd874e58-88b9-4010-8c71-9cf1ad67d093",
   "metadata": {},
   "source": [
    "### ML Model Raodmap\n",
    "1. Read the data\n",
    "2. Explore the data\n",
    "\n",
    "3. Processing\n",
    "    - Numerical features (scaling)\n",
    "    \n",
    "4. Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf2f3b2e-20e1-4021-ab07-7bbd6d64baed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================== #\n",
    "#        Implementing ModelCheckpoint \n",
    "#        Callback with Synthetic data\n",
    "# ==================================================== #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0736b4d9-543e-4b3a-8e02-15256d9200fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Cover Type dataset...\n",
      "Dataset shape: (581012, 54)\n",
      "Number of classes: 7\n",
      "Scaling features...\n",
      "Converting targets to one-hot encoding...\n",
      "Splitting dataset...\n",
      "\n",
      "Starting model training...\n",
      "Epoch 1/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6043 - loss: 1.1912\n",
      "Epoch 1: val_accuracy improved from -inf to 0.74090, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_acc.keras\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.62000, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_loss.keras\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.6045 - loss: 1.1904 - val_accuracy: 0.7409 - val_loss: 0.6200 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m362/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7290 - loss: 0.6560\n",
      "Epoch 2: val_accuracy improved from 0.74090 to 0.76913, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_acc.keras\n",
      "\n",
      "Epoch 2: val_loss improved from 0.62000 to 0.54121, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_loss.keras\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 20ms/step - accuracy: 0.7290 - loss: 0.6558 - val_accuracy: 0.7691 - val_loss: 0.5412 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m363/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7504 - loss: 0.5877\n",
      "Epoch 3: val_accuracy improved from 0.76913 to 0.78363, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_acc.keras\n",
      "\n",
      "Epoch 3: val_loss improved from 0.54121 to 0.50360, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_loss.keras\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.7504 - loss: 0.5877 - val_accuracy: 0.7836 - val_loss: 0.5036 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7599 - loss: 0.5587\n",
      "Epoch 4: val_accuracy improved from 0.78363 to 0.79736, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_acc.keras\n",
      "\n",
      "Epoch 4: val_loss improved from 0.50360 to 0.47835, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_loss.keras\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.7599 - loss: 0.5587 - val_accuracy: 0.7974 - val_loss: 0.4783 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7724 - loss: 0.5323\n",
      "Epoch 5: val_accuracy improved from 0.79736 to 0.80758, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_acc.keras\n",
      "\n",
      "Epoch 5: val_loss improved from 0.47835 to 0.45866, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_loss.keras\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.7724 - loss: 0.5323 - val_accuracy: 0.8076 - val_loss: 0.4587 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7791 - loss: 0.5153\n",
      "Epoch 6: val_accuracy improved from 0.80758 to 0.81326, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_acc.keras\n",
      "\n",
      "Epoch 6: val_loss improved from 0.45866 to 0.44236, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_loss.keras\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.7791 - loss: 0.5153 - val_accuracy: 0.8133 - val_loss: 0.4424 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m362/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7890 - loss: 0.4964\n",
      "Epoch 7: val_accuracy improved from 0.81326 to 0.82273, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_acc.keras\n",
      "\n",
      "Epoch 7: val_loss improved from 0.44236 to 0.41886, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_loss.keras\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.7890 - loss: 0.4964 - val_accuracy: 0.8227 - val_loss: 0.4189 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7960 - loss: 0.4807\n",
      "Epoch 8: val_accuracy improved from 0.82273 to 0.82960, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_acc.keras\n",
      "\n",
      "Epoch 8: val_loss improved from 0.41886 to 0.40517, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_loss.keras\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.7960 - loss: 0.4807 - val_accuracy: 0.8296 - val_loss: 0.4052 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8009 - loss: 0.4682\n",
      "Epoch 9: val_accuracy improved from 0.82960 to 0.83545, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_acc.keras\n",
      "\n",
      "Epoch 9: val_loss improved from 0.40517 to 0.39201, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_loss.keras\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.8009 - loss: 0.4682 - val_accuracy: 0.8354 - val_loss: 0.3920 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8065 - loss: 0.4562\n",
      "Epoch 10: val_accuracy improved from 0.83545 to 0.83890, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_acc.keras\n",
      "\n",
      "Epoch 10: val_loss improved from 0.39201 to 0.38161, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_loss.keras\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.8065 - loss: 0.4562 - val_accuracy: 0.8389 - val_loss: 0.3816 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8100 - loss: 0.4481\n",
      "Epoch 11: val_accuracy improved from 0.83890 to 0.84454, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_acc.keras\n",
      "\n",
      "Epoch 11: val_loss improved from 0.38161 to 0.36970, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_loss.keras\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.8100 - loss: 0.4481 - val_accuracy: 0.8445 - val_loss: 0.3697 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8161 - loss: 0.4354\n",
      "Epoch 12: val_accuracy improved from 0.84454 to 0.84923, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_acc.keras\n",
      "\n",
      "Epoch 12: val_loss improved from 0.36970 to 0.36095, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_loss.keras\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.8161 - loss: 0.4354 - val_accuracy: 0.8492 - val_loss: 0.3609 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8180 - loss: 0.4297\n",
      "Epoch 13: val_accuracy improved from 0.84923 to 0.85241, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_acc.keras\n",
      "\n",
      "Epoch 13: val_loss improved from 0.36095 to 0.35298, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_loss.keras\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.8180 - loss: 0.4297 - val_accuracy: 0.8524 - val_loss: 0.3530 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8208 - loss: 0.4239\n",
      "Epoch 14: val_accuracy improved from 0.85241 to 0.85632, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_acc.keras\n",
      "\n",
      "Epoch 14: val_loss improved from 0.35298 to 0.34595, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_loss.keras\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.8208 - loss: 0.4239 - val_accuracy: 0.8563 - val_loss: 0.3459 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m362/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8262 - loss: 0.4161\n",
      "Epoch 15: val_accuracy improved from 0.85632 to 0.85815, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_acc.keras\n",
      "\n",
      "Epoch 15: val_loss improved from 0.34595 to 0.33864, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_loss.keras\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.8262 - loss: 0.4161 - val_accuracy: 0.8581 - val_loss: 0.3386 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8270 - loss: 0.4127\n",
      "Epoch 16: val_accuracy improved from 0.85815 to 0.86313, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_acc.keras\n",
      "\n",
      "Epoch 16: val_loss improved from 0.33864 to 0.33424, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_loss.keras\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.8270 - loss: 0.4127 - val_accuracy: 0.8631 - val_loss: 0.3342 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8308 - loss: 0.4048\n",
      "Epoch 17: val_accuracy improved from 0.86313 to 0.86463, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_acc.keras\n",
      "\n",
      "Epoch 17: val_loss improved from 0.33424 to 0.32995, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_loss.keras\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.8308 - loss: 0.4048 - val_accuracy: 0.8646 - val_loss: 0.3300 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8314 - loss: 0.4025\n",
      "Epoch 18: val_accuracy improved from 0.86463 to 0.86647, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_acc.keras\n",
      "\n",
      "Epoch 18: val_loss improved from 0.32995 to 0.32342, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_loss.keras\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.8314 - loss: 0.4025 - val_accuracy: 0.8665 - val_loss: 0.3234 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8335 - loss: 0.3986\n",
      "Epoch 19: val_accuracy improved from 0.86647 to 0.86697, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_acc.keras\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.32342\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.8335 - loss: 0.3986 - val_accuracy: 0.8670 - val_loss: 0.3238 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m363/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8360 - loss: 0.3938\n",
      "Epoch 20: val_accuracy improved from 0.86697 to 0.87015, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_acc.keras\n",
      "\n",
      "Epoch 20: val_loss improved from 0.32342 to 0.31511, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_loss.keras\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.8360 - loss: 0.3938 - val_accuracy: 0.8702 - val_loss: 0.3151 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8367 - loss: 0.3904\n",
      "Epoch 21: val_accuracy improved from 0.87015 to 0.87190, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_acc.keras\n",
      "\n",
      "Epoch 21: val_loss improved from 0.31511 to 0.31167, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_loss.keras\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.8367 - loss: 0.3904 - val_accuracy: 0.8719 - val_loss: 0.3117 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m363/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8386 - loss: 0.3874\n",
      "Epoch 22: val_accuracy improved from 0.87190 to 0.87346, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_acc.keras\n",
      "\n",
      "Epoch 22: val_loss improved from 0.31167 to 0.30746, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_loss.keras\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.8386 - loss: 0.3874 - val_accuracy: 0.8735 - val_loss: 0.3075 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8400 - loss: 0.3844\n",
      "Epoch 23: val_accuracy improved from 0.87346 to 0.87460, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_acc.keras\n",
      "\n",
      "Epoch 23: val_loss improved from 0.30746 to 0.30419, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_loss.keras\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.8400 - loss: 0.3844 - val_accuracy: 0.8746 - val_loss: 0.3042 - learning_rate: 0.0010\n",
      "Epoch 24/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8398 - loss: 0.3829\n",
      "Epoch 24: val_accuracy improved from 0.87460 to 0.87527, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_acc.keras\n",
      "\n",
      "Epoch 24: val_loss improved from 0.30419 to 0.30327, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_loss.keras\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.8398 - loss: 0.3829 - val_accuracy: 0.8753 - val_loss: 0.3033 - learning_rate: 0.0010\n",
      "Epoch 25/50\n",
      "\u001b[1m363/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8428 - loss: 0.3780\n",
      "Epoch 25: val_accuracy improved from 0.87527 to 0.87629, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_acc.keras\n",
      "\n",
      "Epoch 25: val_loss improved from 0.30327 to 0.29970, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_loss.keras\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.8428 - loss: 0.3780 - val_accuracy: 0.8763 - val_loss: 0.2997 - learning_rate: 0.0010\n",
      "Epoch 26/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8439 - loss: 0.3760\n",
      "Epoch 26: val_accuracy improved from 0.87629 to 0.87790, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_acc.keras\n",
      "\n",
      "Epoch 26: val_loss improved from 0.29970 to 0.29634, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_loss.keras\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.8439 - loss: 0.3760 - val_accuracy: 0.8779 - val_loss: 0.2963 - learning_rate: 0.0010\n",
      "Epoch 27/50\n",
      "\u001b[1m362/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8442 - loss: 0.3737\n",
      "Epoch 27: val_accuracy improved from 0.87790 to 0.87844, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_acc.keras\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.29634\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.8442 - loss: 0.3737 - val_accuracy: 0.8784 - val_loss: 0.2978 - learning_rate: 0.0010\n",
      "Epoch 28/50\n",
      "\u001b[1m362/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8450 - loss: 0.3728\n",
      "Epoch 28: val_accuracy improved from 0.87844 to 0.88116, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_acc.keras\n",
      "\n",
      "Epoch 28: val_loss improved from 0.29634 to 0.29140, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_loss.keras\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 20ms/step - accuracy: 0.8450 - loss: 0.3728 - val_accuracy: 0.8812 - val_loss: 0.2914 - learning_rate: 0.0010\n",
      "Epoch 29/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8460 - loss: 0.3702\n",
      "Epoch 29: val_accuracy improved from 0.88116 to 0.88194, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_acc.keras\n",
      "\n",
      "Epoch 29: val_loss improved from 0.29140 to 0.28878, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_loss.keras\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.8460 - loss: 0.3702 - val_accuracy: 0.8819 - val_loss: 0.2888 - learning_rate: 0.0010\n",
      "Epoch 30/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8470 - loss: 0.3680\n",
      "Epoch 30: val_accuracy improved from 0.88194 to 0.88223, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_acc.keras\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.28878\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.8470 - loss: 0.3680 - val_accuracy: 0.8822 - val_loss: 0.2895 - learning_rate: 0.0010\n",
      "Epoch 31/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8483 - loss: 0.3657\n",
      "Epoch 31: val_accuracy improved from 0.88223 to 0.88369, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_acc.keras\n",
      "\n",
      "Epoch 31: val_loss improved from 0.28878 to 0.28587, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_loss.keras\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.8483 - loss: 0.3657 - val_accuracy: 0.8837 - val_loss: 0.2859 - learning_rate: 0.0010\n",
      "Epoch 32/50\n",
      "\u001b[1m362/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8500 - loss: 0.3634\n",
      "Epoch 32: val_accuracy improved from 0.88369 to 0.88533, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_acc.keras\n",
      "\n",
      "Epoch 32: val_loss improved from 0.28587 to 0.28371, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_loss.keras\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 20ms/step - accuracy: 0.8500 - loss: 0.3634 - val_accuracy: 0.8853 - val_loss: 0.2837 - learning_rate: 0.0010\n",
      "Epoch 33/50\n",
      "\u001b[1m363/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8489 - loss: 0.3637\n",
      "Epoch 33: val_accuracy improved from 0.88533 to 0.88594, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_acc.keras\n",
      "\n",
      "Epoch 33: val_loss improved from 0.28371 to 0.28213, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_loss.keras\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.8489 - loss: 0.3637 - val_accuracy: 0.8859 - val_loss: 0.2821 - learning_rate: 0.0010\n",
      "Epoch 34/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8481 - loss: 0.3651\n",
      "Epoch 34: val_accuracy improved from 0.88594 to 0.88622, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_acc.keras\n",
      "\n",
      "Epoch 34: val_loss improved from 0.28213 to 0.28061, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_loss.keras\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.8481 - loss: 0.3651 - val_accuracy: 0.8862 - val_loss: 0.2806 - learning_rate: 0.0010\n",
      "Epoch 35/50\n",
      "\u001b[1m363/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8517 - loss: 0.3608\n",
      "Epoch 35: val_accuracy improved from 0.88622 to 0.88726, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_acc.keras\n",
      "\n",
      "Epoch 35: val_loss improved from 0.28061 to 0.28029, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_loss.keras\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.8517 - loss: 0.3608 - val_accuracy: 0.8873 - val_loss: 0.2803 - learning_rate: 0.0010\n",
      "Epoch 36/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8513 - loss: 0.3590\n",
      "Epoch 36: val_accuracy improved from 0.88726 to 0.88742, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_acc.keras\n",
      "\n",
      "Epoch 36: val_loss improved from 0.28029 to 0.27799, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_loss.keras\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.8513 - loss: 0.3590 - val_accuracy: 0.8874 - val_loss: 0.2780 - learning_rate: 0.0010\n",
      "Epoch 37/50\n",
      "\u001b[1m363/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8512 - loss: 0.3580\n",
      "Epoch 37: val_accuracy improved from 0.88742 to 0.88928, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_acc.keras\n",
      "\n",
      "Epoch 37: val_loss improved from 0.27799 to 0.27637, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_loss.keras\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 20ms/step - accuracy: 0.8512 - loss: 0.3580 - val_accuracy: 0.8893 - val_loss: 0.2764 - learning_rate: 0.0010\n",
      "Epoch 38/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8523 - loss: 0.3569\n",
      "Epoch 38: val_accuracy did not improve from 0.88928\n",
      "\n",
      "Epoch 38: val_loss improved from 0.27637 to 0.27334, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_loss.keras\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.8523 - loss: 0.3569 - val_accuracy: 0.8883 - val_loss: 0.2733 - learning_rate: 0.0010\n",
      "Epoch 39/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8537 - loss: 0.3569\n",
      "Epoch 39: val_accuracy improved from 0.88928 to 0.88944, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_acc.keras\n",
      "\n",
      "Epoch 39: val_loss improved from 0.27334 to 0.27186, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_loss.keras\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.8537 - loss: 0.3569 - val_accuracy: 0.8894 - val_loss: 0.2719 - learning_rate: 0.0010\n",
      "Epoch 40/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8529 - loss: 0.3538\n",
      "Epoch 40: val_accuracy did not improve from 0.88944\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.27186\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.8529 - loss: 0.3538 - val_accuracy: 0.8892 - val_loss: 0.2724 - learning_rate: 0.0010\n",
      "Epoch 41/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8542 - loss: 0.3525\n",
      "Epoch 41: val_accuracy improved from 0.88944 to 0.89066, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_acc.keras\n",
      "\n",
      "Epoch 41: val_loss improved from 0.27186 to 0.27018, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_loss.keras\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 20ms/step - accuracy: 0.8542 - loss: 0.3525 - val_accuracy: 0.8907 - val_loss: 0.2702 - learning_rate: 0.0010\n",
      "Epoch 42/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8543 - loss: 0.3536\n",
      "Epoch 42: val_accuracy did not improve from 0.89066\n",
      "\n",
      "Epoch 42: val_loss improved from 0.27018 to 0.26884, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_loss.keras\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.8543 - loss: 0.3536 - val_accuracy: 0.8898 - val_loss: 0.2688 - learning_rate: 0.0010\n",
      "Epoch 43/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8562 - loss: 0.3503\n",
      "Epoch 43: val_accuracy improved from 0.89066 to 0.89127, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_acc.keras\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.26884\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.8562 - loss: 0.3503 - val_accuracy: 0.8913 - val_loss: 0.2689 - learning_rate: 0.0010\n",
      "Epoch 44/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8553 - loss: 0.3492\n",
      "Epoch 44: val_accuracy improved from 0.89127 to 0.89189, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_acc.keras\n",
      "\n",
      "Epoch 44: val_loss improved from 0.26884 to 0.26731, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_loss.keras\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.8553 - loss: 0.3492 - val_accuracy: 0.8919 - val_loss: 0.2673 - learning_rate: 0.0010\n",
      "Epoch 45/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8557 - loss: 0.3479\n",
      "Epoch 45: val_accuracy improved from 0.89189 to 0.89264, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_acc.keras\n",
      "\n",
      "Epoch 45: val_loss improved from 0.26731 to 0.26540, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_loss.keras\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.8557 - loss: 0.3479 - val_accuracy: 0.8926 - val_loss: 0.2654 - learning_rate: 0.0010\n",
      "Epoch 46/50\n",
      "\u001b[1m363/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8569 - loss: 0.3479\n",
      "Epoch 46: val_accuracy did not improve from 0.89264\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.26540\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.8569 - loss: 0.3479 - val_accuracy: 0.8922 - val_loss: 0.2673 - learning_rate: 0.0010\n",
      "Epoch 47/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8569 - loss: 0.3469\n",
      "Epoch 47: val_accuracy improved from 0.89264 to 0.89514, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_acc.keras\n",
      "\n",
      "Epoch 47: val_loss improved from 0.26540 to 0.26354, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_loss.keras\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.8569 - loss: 0.3469 - val_accuracy: 0.8951 - val_loss: 0.2635 - learning_rate: 0.0010\n",
      "Epoch 48/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8582 - loss: 0.3439\n",
      "Epoch 48: val_accuracy did not improve from 0.89514\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.26354\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.8582 - loss: 0.3439 - val_accuracy: 0.8936 - val_loss: 0.2640 - learning_rate: 0.0010\n",
      "Epoch 49/50\n",
      "\u001b[1m362/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8589 - loss: 0.3420\n",
      "Epoch 49: val_accuracy did not improve from 0.89514\n",
      "\n",
      "Epoch 49: val_loss improved from 0.26354 to 0.26294, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_loss.keras\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 20ms/step - accuracy: 0.8589 - loss: 0.3421 - val_accuracy: 0.8951 - val_loss: 0.2629 - learning_rate: 0.0010\n",
      "Epoch 50/50\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8584 - loss: 0.3438\n",
      "Epoch 50: val_accuracy did not improve from 0.89514\n",
      "\n",
      "Epoch 50: val_loss improved from 0.26294 to 0.26243, saving model to covtype_training_20241230_174714/checkpoints/model_best_val_loss.keras\n",
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.8584 - loss: 0.3438 - val_accuracy: 0.8930 - val_loss: 0.2624 - learning_rate: 0.0010\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "\n",
      "Evaluating model on test set...\n",
      "\u001b[1m3632/3632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.8943 - loss: 0.2609\n",
      "\n",
      "Test set results:\n",
      "loss: 0.2616\n",
      "compile_metrics: 0.8939\n",
      "\n",
      "Training Summary:\n",
      "Best validation accuracy: 0.8951\n",
      "Best validation loss: 0.2624\n",
      "Final validation accuracy: 0.8930\n",
      "Final validation loss: 0.2624\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "def load_and_preprocess_data(test_size=0.2):\n",
    "    \"\"\"\n",
    "    Load and preprocess the Forest Cover Type dataset with memory efficient handling\n",
    "    \"\"\"\n",
    "    print(\"Loading Cover Type dataset...\")\n",
    "    data = fetch_covtype()\n",
    "    X = data.data\n",
    "    y = data.target - 1  # Adjust classes to be 0-based\n",
    "    \n",
    "    print(f\"Dataset shape: {X.shape}\")\n",
    "    print(f\"Number of classes: {len(np.unique(y))}\")\n",
    "    \n",
    "    # Scale features\n",
    "    print(\"Scaling features...\")\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Convert to categorical (one-hot encoding)\n",
    "    print(\"Converting targets to one-hot encoding...\")\n",
    "    y_categorical = to_categorical(y)\n",
    "    \n",
    "    # Split the data\n",
    "    print(\"Splitting dataset...\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y_categorical,\n",
    "        test_size=test_size,\n",
    "        random_state=42,\n",
    "        stratify=y  # Maintain class distribution\n",
    "    )\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def create_model(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    Create a model architecture suitable for the Cover Type dataset\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        tf.keras.layers.Input(shape = input_shape),\n",
    "        tf.keras.layers.Dense(256, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        \n",
    "        # Hidden layers\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        \n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        \n",
    "        # Output layer\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def setup_callbacks(experiment_name):\n",
    "    \"\"\"\n",
    "    Setup training callbacks with logging\n",
    "    \"\"\"\n",
    "    # Create directories for checkpoints and logs\n",
    "    base_dir = f'covtype_training_{experiment_name}'\n",
    "    checkpoint_dir = os.path.join(base_dir, 'checkpoints')\n",
    "    logs_dir = os.path.join(base_dir, 'logs')\n",
    "    \n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    os.makedirs(logs_dir, exist_ok=True)\n",
    "    \n",
    "    callbacks = [\n",
    "        # Model checkpoint to save best models\n",
    "        ModelCheckpoint(\n",
    "            filepath=os.path.join(checkpoint_dir, 'model_best_val_acc.keras'),\n",
    "            monitor='val_accuracy',\n",
    "            mode='max',\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        \n",
    "        # Another checkpoint to save best models by loss\n",
    "        ModelCheckpoint(\n",
    "            filepath=os.path.join(checkpoint_dir, 'model_best_val_loss.keras'),\n",
    "            monitor='val_loss',\n",
    "            mode='min',\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        \n",
    "        # Early stopping to prevent overfitting\n",
    "        EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=5,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        \n",
    "        # Reduce learning rate when training plateaus\n",
    "        ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=3,\n",
    "            min_lr=1e-6,\n",
    "            verbose=1\n",
    "        ),\n",
    "        \n",
    "        # CSV Logger to track all metrics\n",
    "        CSVLogger(\n",
    "            os.path.join(logs_dir, 'training_log.csv'),\n",
    "            append=True\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    return callbacks\n",
    "\n",
    "def train_model():\n",
    "    \"\"\"\n",
    "    Main training function\n",
    "    \"\"\"\n",
    "    # Load and preprocess data\n",
    "    X_train, X_test, y_train, y_test = load_and_preprocess_data()\n",
    "    \n",
    "    # Create model\n",
    "    num_classes = y_train.shape[1]\n",
    "    model = create_model((X_train.shape[1],), num_classes)\n",
    "    \n",
    "    # Setup callbacks\n",
    "    experiment_name = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    callbacks = setup_callbacks(experiment_name)\n",
    "    \n",
    "    # Train model\n",
    "    print(\"\\nStarting model training...\")\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_split=0.2,\n",
    "        epochs=50,\n",
    "        batch_size=1024,  # Large batch size for efficiency\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    print(\"\\nEvaluating model on test set...\")\n",
    "    test_results = model.evaluate(X_test, y_test, verbose=1)\n",
    "    print(f\"\\nTest set results:\")\n",
    "    for metric_name, value in zip(model.metrics_names, test_results):\n",
    "        print(f\"{metric_name}: {value:.4f}\")\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "\n",
    "def analyze_training_results(history, experiment_name):\n",
    "    \"\"\"\n",
    "    Analyze and save training history\n",
    "    \"\"\"\n",
    "    # Convert history to dataframe\n",
    "    history_df = pd.DataFrame(history.history)\n",
    "    \n",
    "    # Save history to csv\n",
    "    results_dir = f'covtype_training_{experiment_name}/analysis'\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    history_df.to_csv(os.path.join(results_dir, 'training_history.csv'))\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"\\nTraining Summary:\")\n",
    "    print(f\"Best validation accuracy: {max(history.history['val_accuracy']):.4f}\")\n",
    "    print(f\"Best validation loss: {min(history.history['val_loss']):.4f}\")\n",
    "    print(f\"Final validation accuracy: {history.history['val_accuracy'][-1]:.4f}\")\n",
    "    print(f\"Final validation loss: {history.history['val_loss'][-1]:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model, history = train_model()\n",
    "    analyze_training_results(history, datetime.now().strftime(\"%Y%m%d_%H%M%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d05fd1-5a15-4638-a6d3-e3d3b6ce4c91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98210a6e-1667-442f-9f7b-1a7b179f7e6a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cleanup_directory' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Cleanup \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m cleanup_directory(checkpoint_dir)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cleanup_directory' is not defined"
     ]
    }
   ],
   "source": [
    "# Cleanup \n",
    "cleanup_directory(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595397ce-f507-482c-8040-3e4bf2ee8fc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF-GPU:2.16",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
