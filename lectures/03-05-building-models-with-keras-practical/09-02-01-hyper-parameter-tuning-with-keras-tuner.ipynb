{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "297156c1-7deb-4c1d-b601-7a156476a408",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center;font-size:22pt; font-weight:bold;color:white;border:solid black 1.5pt;background-color:#1e7263;\">\n",
    "    TensorBoard Callback Overview\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "131fa24a-96cf-4cc5-a2a7-945b355942c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================= #\n",
    "# Course: Deep Learning Complete Course (CS-501)\n",
    "# Author: Dr. Saad Laouadi\n",
    "# Institution: Quant Coding Versity Academy\n",
    "#\n",
    "# ==========================================================\n",
    "# Lesson: Understanding tensorboard callback\n",
    "#         Synthetic Data Example\n",
    "# ==========================================================\n",
    "# ## Learning Objectives\n",
    "# This example will enable you to:\n",
    "# 1. Understand the tensorboard callback\n",
    "# 2. Setup the environment for using tensorboard\n",
    "# =======================================================================\n",
    "#          Copyright Â© Dr. Saad Laouadi 2025\n",
    "# ======================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db04498-44c4-434f-8e8b-cec78e0419b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================ #\n",
    "#                         Environment Path Configuration                       #\n",
    "# ============================================================================ #\n",
    "#\n",
    "# Purpose:\n",
    "#   Configure the system PATH to use Python executables from the active virtual \n",
    "#   environment instead of global installations.\n",
    "#\n",
    "# Usage:\n",
    "#   1. First verify if configuration is needed by running: !which python\n",
    "#   2. If the output shows the global Python installation rather than your \n",
    "#      virtual environment, execute this configuration block\n",
    "#\n",
    "# Note:\n",
    "#   This configuration is typically only needed for JupyterLab Desktop or \n",
    "#   similar standalone installations. Web-based JupyterLab or properly \n",
    "#   configured environments should not require this adjustment.\n",
    "# ============================================================================ #\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "env_path = os.path.dirname(sys.executable)\n",
    "os.environ['PATH'] = f\"{env_path}:{os.environ['PATH']}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c26ca844-8301-46b7-89da-e2dca2248ec4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================\n",
      "Author: Dr. Saad Laouadi\n",
      "\n",
      "Last updated: 2024-12-31\n",
      "\n",
      "Compiler    : Clang 14.0.6 \n",
      "OS          : Darwin\n",
      "Release     : 24.1.0\n",
      "Machine     : arm64\n",
      "Processor   : arm\n",
      "CPU cores   : 16\n",
      "Architecture: 64bit\n",
      "\n",
      "========================================================================\n",
      "Imported Packages and Their Versions:\n",
      "========================================================================\n",
      "sklearn   : 1.5.1\n",
      "keras     : 3.6.0\n",
      "matplotlib: 3.9.2\n",
      "tensorflow: 2.16.2\n",
      "seaborn   : 0.13.2\n",
      "numpy     : 1.26.4\n",
      "pandas    : 2.2.2\n",
      "\n",
      "========================================================================\n"
     ]
    }
   ],
   "source": [
    "# ==================================================== #\n",
    "#        Load Required Libraries\n",
    "# ==================================================== #\n",
    "\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import io\n",
    "\n",
    "\n",
    "# Disable Metal API Validation\n",
    "os.environ[\"METAL_DEVICE_WRAPPER_TYPE\"] = \"0\"  \n",
    "\n",
    "# import tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"=\"*72)\n",
    "\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Dr. Saad Laouadi\" -u -d -m\n",
    "\n",
    "print(\"=\"*72)\n",
    "print(\"Imported Packages and Their Versions:\")\n",
    "print(\"=\"*72)\n",
    "\n",
    "%watermark -iv\n",
    "print(\"=\"*72)\n",
    "\n",
    "# Global Config\n",
    "RANDOM_STATE = 101"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e90bc1f-299a-49ed-8a89-023723a0dc83",
   "metadata": {},
   "source": [
    "# Modern Hyperparameter Tuning with Keras: A Comprehensive Guide\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The `tensorflow.keras.wrappers.scikit_learn` module, which previously provided the `KerasClassifier` and `KerasRegressor` wrappers, has been deprecated. This guide presents modern approaches to hyperparameter tuning for Keras models, offering both alternative solutions and best practices.\n",
    "\n",
    "## Modern Alternatives\n",
    "\n",
    "### 1. Using Keras Tuner\n",
    "\n",
    "Keras Tuner is the official hyperparameter tuning library for Keras, offering a more powerful and flexible approach than the old scikit-learn wrappers.\n",
    "\n",
    "```python\n",
    "import keras_tuner as kt\n",
    "from tensorflow import keras\n",
    "\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    # Tune number of units in the first dense layer\n",
    "    hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
    "    model.add(keras.layers.Dense(units=hp_units, activation='relu'))\n",
    "    \n",
    "    # Tune dropout rate\n",
    "    hp_dropout = hp.Float('dropout', min_value=0.0, max_value=0.5, step=0.1)\n",
    "    model.add(keras.layers.Dropout(hp_dropout))\n",
    "    \n",
    "    # Tune learning rate\n",
    "    hp_learning_rate = hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='log')\n",
    "    \n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                 loss='categorical_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Initialize tuner\n",
    "tuner = kt.Hyperband(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=30,\n",
    "    factor=3,\n",
    "    directory='keras_tuner',\n",
    "    project_name='hyperparameter_optimization'\n",
    ")\n",
    "\n",
    "# Perform hyperparameter search\n",
    "tuner.search(x_train, y_train,\n",
    "            epochs=30,\n",
    "            validation_data=(x_val, y_val),\n",
    "            callbacks=[keras.callbacks.EarlyStopping(patience=5)])\n",
    "\n",
    "# Get best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "```\n",
    "\n",
    "### 2. Custom Scikit-learn Compatible Wrapper\n",
    "\n",
    "If you still need scikit-learn compatibility, you can create a custom wrapper:\n",
    "\n",
    "```python\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "import numpy as np\n",
    "\n",
    "class KerasClassifierWrapper(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, model_fn, **kwargs):\n",
    "        self.model_fn = model_fn\n",
    "        self.kwargs = kwargs\n",
    "        self.model = None\n",
    "        \n",
    "    def fit(self, X, y, **kwargs):\n",
    "        if self.model is None:\n",
    "            self.model = self.model_fn(**self.kwargs)\n",
    "        \n",
    "        # Convert y to one-hot if needed\n",
    "        if len(y.shape) == 1:\n",
    "            y = keras.utils.to_categorical(y)\n",
    "            \n",
    "        self.model.fit(X, y, **kwargs)\n",
    "        return self\n",
    "        \n",
    "    def predict(self, X):\n",
    "        predictions = self.model.predict(X)\n",
    "        return np.argmax(predictions, axis=1)\n",
    "        \n",
    "    def predict_proba(self, X):\n",
    "        return self.model.predict(X)\n",
    "\n",
    "# Usage example:\n",
    "def create_model(units=64, dropout=0.2, learning_rate=0.001):\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(units, activation='relu'),\n",
    "        keras.layers.Dropout(dropout),\n",
    "        keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Create wrapped classifier\n",
    "classifier = KerasClassifierWrapper(\n",
    "    model_fn=create_model,\n",
    "    units=64,\n",
    "    dropout=0.2,\n",
    "    learning_rate=0.001\n",
    ")\n",
    "```\n",
    "\n",
    "### 3. Integration with Scikit-learn's GridSearchCV\n",
    "\n",
    "Using the custom wrapper with GridSearchCV:\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'units': [32, 64, 128],\n",
    "    'dropout': [0.1, 0.2, 0.3],\n",
    "    'learning_rate': [0.001, 0.01]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=KerasClassifierWrapper(create_model),\n",
    "    param_grid=param_grid,\n",
    "    cv=3,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=1  # Use 1 for GPU training\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "## Best Practices for Hyperparameter Tuning\n",
    "\n",
    "### 1. Search Space Design\n",
    "\n",
    "When defining hyperparameter search spaces, consider these guidelines:\n",
    "\n",
    "- Learning rate: Use log-uniform distribution (e.g., 1e-4 to 1e-2)\n",
    "- Number of units: Use uniform distribution with exponential steps (32, 64, 128, etc.)\n",
    "- Dropout rate: Linear space between 0.0 and 0.5\n",
    "- Batch size: Powers of 2 (32, 64, 128, etc.)\n",
    "\n",
    "### 2. Cross-Validation Strategy\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "```\n",
    "\n",
    "### 3. Resource Management\n",
    "\n",
    "- Use early stopping to prevent overfitting and save computational resources\n",
    "- Implement learning rate scheduling\n",
    "- Monitor GPU memory usage\n",
    "\n",
    "```python\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.2,\n",
    "        patience=3,\n",
    "        min_lr=1e-6\n",
    "    )\n",
    "]\n",
    "```\n",
    "\n",
    "## Advanced Techniques\n",
    "\n",
    "### 1. Bayesian Optimization\n",
    "\n",
    "Using `scikit-optimize` for Bayesian optimization:\n",
    "\n",
    "```python\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer\n",
    "\n",
    "search_spaces = {\n",
    "    'learning_rate': Real(1e-4, 1e-2, prior='log-uniform'),\n",
    "    'units': Integer(32, 512),\n",
    "    'dropout': Real(0.0, 0.5)\n",
    "}\n",
    "\n",
    "bayes_search = BayesSearchCV(\n",
    "    KerasClassifierWrapper(create_model),\n",
    "    search_spaces,\n",
    "    n_iter=50,\n",
    "    cv=3,\n",
    "    scoring='accuracy'\n",
    ")\n",
    "```\n",
    "\n",
    "### 2. Population-Based Training\n",
    "\n",
    "For advanced users, population-based training combines hyperparameter optimization with neural architecture search:\n",
    "\n",
    "```python\n",
    "import ray\n",
    "from ray import tune\n",
    "\n",
    "def train_func(config):\n",
    "    model = create_model(**config)\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=30,\n",
    "        callbacks=[keras.callbacks.EarlyStopping(patience=5)]\n",
    "    )\n",
    "    tune.report(accuracy=max(history.history['val_accuracy']))\n",
    "\n",
    "analysis = tune.run(\n",
    "    train_func,\n",
    "    config={\n",
    "        \"units\": tune.grid_search([32, 64, 128]),\n",
    "        \"dropout\": tune.uniform(0.0, 0.5),\n",
    "        \"learning_rate\": tune.loguniform(1e-4, 1e-2)\n",
    "    },\n",
    "    num_samples=50\n",
    ")\n",
    "```\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "While the deprecation of `keras.wrappers.scikit_learn` may initially seem challenging, modern alternatives offer more powerful and flexible approaches to hyperparameter tuning. The combination of Keras Tuner, custom wrappers, and advanced optimization techniques provides a robust framework for developing and optimizing deep learning models.\n",
    "\n",
    "Remember to:\n",
    "1. Choose the appropriate tuning strategy based on your computational resources\n",
    "2. Design meaningful search spaces for your hyperparameters\n",
    "3. Implement proper cross-validation and early stopping\n",
    "4. Monitor and manage computational resources effectively\n",
    "\n",
    "By following these guidelines and leveraging modern tools, you can achieve better results in hyperparameter optimization for your Keras models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30c37a0-69fb-4194-8d7d-1d8dc7793e06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF-GPU:2.16",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
