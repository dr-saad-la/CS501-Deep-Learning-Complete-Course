{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27df21aa-9518-4f05-b8d8-a423509a7df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================= #\n",
    "# Course: Deep Learning Complete Course (CS-501)\n",
    "# Author: Dr. Saad Laouadi\n",
    "# \n",
    "# \n",
    "# =======================================================================\n",
    "# Module: Binary Classification Practice Exercise\n",
    "# Topic: Iris Classification with Neural Networks\n",
    "# =======================================================================\n",
    "# Learning Objectives:\n",
    "# 1. Apply classification concepts to a new dataset\n",
    "# 2. Practice data preparation for multi-class classification\n",
    "# 3. Build and train a neural network classifier\n",
    "# 4. Evaluate model performance\n",
    "# =======================================================================\n",
    "# Prerequisites:\n",
    "# - Completion of Titanic Classification lesson\n",
    "# - Basic understanding of Python and Keras\n",
    "# - Familiarity with data preprocessing\n",
    "# =======================================================================\n",
    "#          Copyright Â© Dr. Saad Laouadi 2024\n",
    "# ======================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68fca4c-6347-4d99-9bf3-64c292ee3be3",
   "metadata": {},
   "source": [
    "### Practice Exercise: Iris Flower Classification\n",
    "\n",
    "Your task is to build a neural network that classifies iris flowers into their respective species.\n",
    "Follow the steps below and fill in the code where indicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad8b65a-6c03-4cf2-b175-035ba735e39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Environment Setup\n",
    "# ------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab10624c-f3eb-48f2-baf1-d71e212a5f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b0a183-5b0d-4038-b791-8ee65bb2afae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1: Data Exploration\n",
    "# -----------------------\n",
    "# 1. Print the shape of X and y to understand the dataset structure\n",
    "# 2. Display the first few samples of the data\n",
    "# 3. Print the target class names (iris.target_names)\n",
    "\n",
    "\n",
    "# Your code here:\n",
    "print(\"Data shape:\", X.shape)\n",
    "print(\"Target shape:\", y.shape)\n",
    "print(\"\\nSample features:\\n\", X[:5])\n",
    "print(\"\\nTarget classes:\", iris.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18cea16-25c9-4da1-8d2f-5574cbad2da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2: Data Preparation\n",
    "# -----------------------\n",
    "# 1. Convert the target variable to categorical format using to_categorical\n",
    "# 2. Split the data into training and validation sets (use train_test_split)\n",
    "\n",
    "# Convert targets to categorical format\n",
    "y_categorical = \n",
    "\n",
    "# Split the data\n",
    "X_train, X_val, y_train, y_val = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c36f192-2ce6-4c9b-8e4c-42cefd74ec6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3: Model Building\n",
    "# ---------------------\n",
    "# TODO: Create a Sequential model with:\n",
    "# - Input layer matching feature dimensions\n",
    "# - One hidden layer with 32 neurons and 'relu' activation\n",
    "# - Output layer with neurons matching number of classes and 'softmax' activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bda8bb-85fe-4618-9176-e62381dd83be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "model = Sequential([\n",
    "    # Add the input layer\n",
    "    \n",
    "    # Add the first hidden layer\n",
    "    \n",
    "    # Add the output layer\n",
    "    \n",
    "])\n",
    "\n",
    "# Print model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732d3389-11bb-4582-b49f-74df08b1c99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 4: Model Compilation\n",
    "# ------------------------\n",
    "# Compile the model with:\n",
    "#       - 'sgd' optimizer\n",
    "#       - 'categorical_crossentropy' loss\n",
    "#       - accuracy metric\n",
    "\n",
    "\n",
    "# Your code here:\n",
    "model.compile(\n",
    "    # Add compilation parameters\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d3f9a9-a4f0-4c49-8653-d0f48dbf4c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 5: Model Training\n",
    "# ---------------------\n",
    "# TODO: Train the model with:\n",
    "# - 25 epochs\n",
    "# - batch_size of 16\n",
    "# - Use the validation data created earlier\n",
    "\n",
    "\n",
    "# Your code here:\n",
    "history = model.fit(\n",
    "    # Add training parameters\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e209009-dbe1-40e2-8b23-9b79a9bf1d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge:\n",
    "# ---------------\n",
    "# 1. Try adding another hidden layer\n",
    "# 2. Experiment with different numbers of neurons\n",
    "# 3. Try using different optimizers (like 'adam')\n",
    "# 4. Plot the training history (accuracy and loss)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37718e7a-5c8d-4f51-b103-d5925537b4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================================\n",
    "# Expected Output:\n",
    "# - Model should achieve at least 80% validation accuracy\n",
    "# - Training and validation loss should decrease over time\n",
    "# - Final model should be able to classify new iris samples accurately\n",
    "# ======================================================================="
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF-GPU:2.16",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
